{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "SINGLES_BASELINE_WIDTH = 8.23\n",
    "DOUBLES_BASELINE_WIDTH = 10.97\n",
    "COURT_LENGTH = 23.77\n",
    "HALF_COURT_LENGTH = COURT_LENGTH / 2  # baseline to net distance\n",
    "SERVICE_BOX_LENGTH = 6.4\n",
    "DOUBLES_ALLEY_WIDTH = 1.37\n",
    "NO_MANS_LAND_LENGTH = HALF_COURT_LENGTH - SERVICE_BOX_LENGTH\n",
    "PLAYER_1_HEIGHT = 1.88\n",
    "PLAYER_2_HEIGHT = 1.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CourtLineDetector:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = models.resnet50(weights=None)\n",
    "        # modify fc layer\n",
    "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, 14*2)\n",
    "        # load saved wts\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),  # (C, H, W) -> (3,224,224)\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def predict(self, image):\n",
    "        \"\"\" predicts the keypoints using the loaded model\n",
    "        Returns:\n",
    "            1-D np arr: x,y coordinates of all 14 keypoints\n",
    "        \"\"\"\n",
    "        # only predict on the 1st frame, because camera remains stationary\n",
    "            # - tennis court remains static across all frames\n",
    "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # model needs inp in a list format for pred\n",
    "        img_tensor = self.transform(img_rgb).unsqueeze(0) # img -[unsqueeze]-> [img]\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(img_tensor)  # (1,28)\n",
    "        keypoints = outputs.squeeze().cpu().numpy()  # (28)\n",
    "\n",
    "        # add additional points as center of baseline\n",
    "        kp_4 = keypoints_to_idx(keypoints, 4)\n",
    "        kp_5 = keypoints_to_idx(keypoints, 5)\n",
    "        kp_6 = keypoints_to_idx(keypoints, 6)\n",
    "        kp_7 = keypoints_to_idx(keypoints, 7)\n",
    "        kp_8 = keypoints_to_idx(keypoints, 8)\n",
    "        kp_9 = keypoints_to_idx(keypoints, 9)\n",
    "        kp_10 = keypoints_to_idx(keypoints, 10)\n",
    "        kp_11 = keypoints_to_idx(keypoints, 11)\n",
    "        kp_12 = keypoints_to_idx(keypoints, 12)\n",
    "        kp_13 = keypoints_to_idx(keypoints, 13)\n",
    "        \n",
    "        kp_14 = midpoint(kp_4, kp_6)\n",
    "        kp_15 = midpoint(kp_5, kp_7)\n",
    "        kp_16 = midpoint(kp_12, kp_13)\n",
    "        kp_17 = midpoint(kp_8, kp_10)\n",
    "        kp_18 = midpoint(kp_9, kp_11)\n",
    "\n",
    "        keypoints = np.append(keypoints, kp_14[0])\n",
    "        keypoints = np.append(keypoints, kp_14[1])\n",
    "        keypoints = np.append(keypoints, kp_15[0])\n",
    "        keypoints = np.append(keypoints, kp_15[1])\n",
    "        keypoints = np.append(keypoints, kp_16[0])\n",
    "        keypoints = np.append(keypoints, kp_16[1])\n",
    "        keypoints = np.append(keypoints, kp_17[0])\n",
    "        keypoints = np.append(keypoints, kp_17[1])\n",
    "        keypoints = np.append(keypoints, kp_18[0])\n",
    "        keypoints = np.append(keypoints, kp_18[1])\n",
    "\n",
    "        # map back transformed img to original img dims\n",
    "        og_h, og_w = img_rgb.shape[:2]\n",
    "        keypoints[::2] *= og_w / 224.0\n",
    "        keypoints[1::2] *= og_h / 224.0\n",
    "\n",
    "        return keypoints  # [x1, y1, x2, y2, x1, y1, x2, y2, ...]\n",
    "    \n",
    "    def draw_keypoints(self, image, keypoints):\n",
    "        for i in range(0, len(keypoints), 2):\n",
    "            if i < 28:\n",
    "                x = int(keypoints[i])\n",
    "                y = int(keypoints[i+1])\n",
    "\n",
    "                # draw dot on the coords\n",
    "                # cv2.putText(image, str(i//2), (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "                cv2.circle(image, (x,y), 5, (0,0,255), -1)  # -1 -> filled circle\n",
    "        return image\n",
    "    \n",
    "    def draw_keypoints_on_video(self, video_frames, keypoints):\n",
    "        output_video_frames = []\n",
    "        for frame in video_frames:\n",
    "            frame = self.draw_keypoints(frame, keypoints)\n",
    "            output_video_frames.append(frame)\n",
    "        return output_video_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniCourt:\n",
    "    def __init__(self, frame):\n",
    "        self.drawing_rectangle_width = 250\n",
    "        self.drawing_rectangle_height = 500\n",
    "        # padding in the frame\n",
    "        self.buffer = 50\n",
    "        # padding in the canvas inside the frame\n",
    "        self.padding_court = 20\n",
    "\n",
    "        self.set_canvas_background_box_position(frame)\n",
    "        self.set_minicourt_position()\n",
    "        self.set_court_drawing_keypoints()\n",
    "        self.set_court_lines()\n",
    "\n",
    "    def convert_meters_to_pixels(self, meters):\n",
    "        return convert_meters_to_pixel_distance(meters, DOUBLES_BASELINE_WIDTH, self.court_drawing_width)\n",
    "\n",
    "    def set_court_drawing_keypoints(self):\n",
    "        drawing_keypoints = [0] * 38\n",
    "        # Doubles Court included -> (topleft, topright, bottomleft, bottomright)\n",
    "        ## point i -> drawing_keypoints([2*i], [2*i+1])\n",
    "        ## point 0\n",
    "        drawing_keypoints[0], drawing_keypoints[1] = int(self.court_start_x), int(self.court_start_y)\n",
    "        ## point 1\n",
    "        drawing_keypoints[2], drawing_keypoints[3] = int(self.court_end_x), int(self.court_start_y)\n",
    "        ## point 2\n",
    "        drawing_keypoints[4] = int(self.court_start_x)\n",
    "        drawing_keypoints[5] = self.court_start_y + self.convert_meters_to_pixels(COURT_LENGTH)\n",
    "        ## point 3\n",
    "        drawing_keypoints[6] = drawing_keypoints[0] + self.court_drawing_width\n",
    "        drawing_keypoints[7] = self.court_start_y + self.convert_meters_to_pixels(COURT_LENGTH)\n",
    "        # Singles Court only -> (topleft, bottomleft, topright, bottomright)\n",
    "        ## point 4\n",
    "        drawing_keypoints[8] = drawing_keypoints[0] + self.convert_meters_to_pixels(DOUBLES_ALLEY_WIDTH)\n",
    "        drawing_keypoints[9] = drawing_keypoints[1]\n",
    "        ## point 5\n",
    "        drawing_keypoints[10] = drawing_keypoints[8]\n",
    "        drawing_keypoints[11] = drawing_keypoints[5]\n",
    "        ## point 6\n",
    "        drawing_keypoints[12] = drawing_keypoints[2] - self.convert_meters_to_pixels(DOUBLES_ALLEY_WIDTH)\n",
    "        drawing_keypoints[13] = drawing_keypoints[3]\n",
    "        ## point 7\n",
    "        drawing_keypoints[14] = drawing_keypoints[6] - self.convert_meters_to_pixels(DOUBLES_ALLEY_WIDTH)\n",
    "        drawing_keypoints[15] = drawing_keypoints[7]\n",
    "        # Service Box -> (topleft, topright, bottomleft, bottomright)\n",
    "        ## point 8\n",
    "        drawing_keypoints[16] = drawing_keypoints[8]\n",
    "        drawing_keypoints[17] = drawing_keypoints[9] + self.convert_meters_to_pixels(NO_MANS_LAND_LENGTH)\n",
    "        ## point 9\n",
    "        drawing_keypoints[18] = drawing_keypoints[16] + self.convert_meters_to_pixels(SINGLES_BASELINE_WIDTH)\n",
    "        drawing_keypoints[19] = drawing_keypoints[17]\n",
    "        ## point 10\n",
    "        drawing_keypoints[20] = drawing_keypoints[10]\n",
    "        drawing_keypoints[21] = drawing_keypoints[11] - self.convert_meters_to_pixels(NO_MANS_LAND_LENGTH)\n",
    "        ## point 11\n",
    "        drawing_keypoints[22] = drawing_keypoints[20] + self.convert_meters_to_pixels(SINGLES_BASELINE_WIDTH)\n",
    "        drawing_keypoints[23] = drawing_keypoints[21]\n",
    "        ## point 12 -> top half T point\n",
    "        drawing_keypoints[24] = int((drawing_keypoints[16] + drawing_keypoints[18]) / 2)\n",
    "        drawing_keypoints[25] = drawing_keypoints[17]\n",
    "        ## point 13 -> bottonm half T point\n",
    "        drawing_keypoints[26] = int((drawing_keypoints[20] + drawing_keypoints[22]) / 2)\n",
    "        drawing_keypoints[27] = drawing_keypoints[21]\n",
    "        # Baseline Center\n",
    "        ## point 14 -> top baseline center\n",
    "        drawing_keypoints[28] = int((drawing_keypoints[8] + drawing_keypoints[12]) / 2)\n",
    "        drawing_keypoints[29] = drawing_keypoints[9]\n",
    "        ## point 15 -> bottom baseline center\n",
    "        drawing_keypoints[30] = int((drawing_keypoints[10] + drawing_keypoints[14]) / 2)\n",
    "        drawing_keypoints[31] = drawing_keypoints[11]\n",
    "        # Net\n",
    "        ## point 16 -> net center\n",
    "        drawing_keypoints[32] = drawing_keypoints[24]\n",
    "        drawing_keypoints[33] = int((drawing_keypoints[25] + drawing_keypoints[27]) / 2)\n",
    "        ## point 17 -> net left\n",
    "        drawing_keypoints[34] = drawing_keypoints[16]\n",
    "        drawing_keypoints[35] = drawing_keypoints[33]\n",
    "        ## point 18 -> net right\n",
    "        drawing_keypoints[36] = drawing_keypoints[18]\n",
    "        drawing_keypoints[37] = drawing_keypoints[33]\n",
    "\n",
    "        self.drawing_keypoints = drawing_keypoints\n",
    "\n",
    "    def set_court_lines(self):\n",
    "        self.lines = [\n",
    "            # each tuple represents a pair of (ith, jth) keypoints\n",
    "            (0,2), \n",
    "            (4,5),\n",
    "            (6,7),\n",
    "            (1,3),\n",
    "\n",
    "            (0,1),\n",
    "            (8,9), \n",
    "            (10,11),\n",
    "            (2,3)\n",
    "        ]\n",
    "\n",
    "    def set_canvas_background_box_position(self, frame):\n",
    "        frame = frame.copy()\n",
    "        self.end_x = frame.shape[1] - self.buffer\n",
    "        self.end_y = self.buffer + self.drawing_rectangle_height\n",
    "        self.start_x = self.end_x - self.drawing_rectangle_width\n",
    "        self.start_y = self.end_y - self.drawing_rectangle_height\n",
    "\n",
    "    def set_minicourt_position(self):\n",
    "        self.court_start_x = self.start_x + self.padding_court\n",
    "        self.court_start_y = self.start_y + self.padding_court\n",
    "        self.court_end_x = self.end_x - self.padding_court\n",
    "        self.court_end_y = self.end_y - self.padding_court\n",
    "        self.court_drawing_width = self.court_end_x - self.court_start_x\n",
    "        self.court_drawing_length = self.court_end_y - self.court_start_y\n",
    "\n",
    "    def draw_court(self, frame):\n",
    "        for i in range(0, len(self.drawing_keypoints), 2):\n",
    "            if i < 28:\n",
    "                x = int(self.drawing_keypoints[i])\n",
    "                y = int(self.drawing_keypoints[i+1])\n",
    "                cv2.circle(frame, (x,y), 5, (0,0,255), -1)\n",
    "        # draw lines\n",
    "        for line in self.lines:\n",
    "            start_point = (int(self.drawing_keypoints[line[0]*2]), int(self.drawing_keypoints[line[0]*2+1]))  # (0,1), (8,9)\n",
    "            end_point = (int(self.drawing_keypoints[line[1]*2]), int(self.drawing_keypoints[line[1]*2+1]))  # (4,5), (10,11)\n",
    "            cv2.line(frame, start_point, end_point, (0,0,0), 2)\n",
    "        # draw net\n",
    "        net_start_point = (self.drawing_keypoints[0], int((self.drawing_keypoints[1] + self.drawing_keypoints[5])/2))\n",
    "        net_end_point = (self.drawing_keypoints[2], int((self.drawing_keypoints[1] + self.drawing_keypoints[5])/2))\n",
    "        cv2.line(frame, net_start_point, net_end_point, (255,0,0), 2)\n",
    "        return frame\n",
    "\n",
    "    def draw_background_rectangle(self, frame):\n",
    "        '''draws a transparent white rectangle on a given frame'''\n",
    "        # fully black image\n",
    "        shapes = np.zeros_like(frame, np.uint8)\n",
    "        # draw a filled white rectangle\n",
    "        cv2.rectangle(shapes, (self.start_x, self.start_y), (self.end_x, self.end_y), (255,255,255), cv2.FILLED)\n",
    "        out = frame.copy()\n",
    "        alpha = 0.5  # frame transparency ratio\n",
    "        beta = 1 - alpha  # shapes_img transparency ratio\n",
    "        mask = shapes.astype(bool)\n",
    "        # blends the frame and shapes_img\n",
    "            # - only modifies pixels in out_img, where mask is True\n",
    "        out[mask] = cv2.addWeighted(frame, alpha, shapes, beta, 0)[mask]\n",
    "        return out\n",
    "    \n",
    "    def draw_minicourt(self, frames):\n",
    "        output_frames = []\n",
    "        for frame in frames:\n",
    "            frame = self.draw_background_rectangle(frame)\n",
    "            frame = self.draw_court(frame)\n",
    "            output_frames.append(frame)\n",
    "        return output_frames\n",
    "    \n",
    "    def get_start_point_of_minicourt(self):\n",
    "        return (self.court_start_x, self.court_end_y)\n",
    "    \n",
    "    def get_width_of_minicourt(self):\n",
    "        return self.court_drawing_width\n",
    "    \n",
    "    def get_length_of_minicourt(self):\n",
    "        return self.court_drawing_length\n",
    "    \n",
    "    def get_court_drawing_keypoints(self):\n",
    "        return self.drawing_keypoints\n",
    "    \n",
    "    def get_minicourt_coordinates(self,\n",
    "                                  object_position,\n",
    "                                  closest_keypoint,\n",
    "                                  closest_keypoint_index,\n",
    "                                  player_height_in_pixels,\n",
    "                                  player_height_in_meters):\n",
    "        '''converts given pos from court dim to minicourt dim'''\n",
    "        # init minicourt obj pos\n",
    "        closest_minicourt_kp = (self.drawing_keypoints[closest_keypoint_index*2],\n",
    "                                self.drawing_keypoints[closest_keypoint_index*2+1])\n",
    "        minicourt_obj_pos = [closest_minicourt_kp[0], closest_minicourt_kp[1]]\n",
    "\n",
    "        # player-to-kp dist\n",
    "        dist_obj_to_kp_x_pixels, dist_obj_to_kp_y_pixels = measure_xy_distance(object_position, closest_keypoint)\n",
    "        ## convert to meters\n",
    "        dist_obj_to_kp_x_meters = convert_pixel_distance_to_meters(dist_obj_to_kp_x_pixels,\n",
    "                                                                 player_height_in_pixels,\n",
    "                                                                 player_height_in_meters)\n",
    "        dist_obj_to_kp_y_meters = convert_pixel_distance_to_meters(dist_obj_to_kp_y_pixels,\n",
    "                                                                 player_height_in_pixels,\n",
    "                                                                 player_height_in_meters)\n",
    "        ## convert back to mini court coords in pixels\n",
    "        minicourt_dist_obj_to_kp_x_pixels = self.convert_meters_to_pixels(dist_obj_to_kp_x_meters)\n",
    "        minicourt_dist_obj_to_kp_y_pixels = self.convert_meters_to_pixels(dist_obj_to_kp_y_meters)\n",
    "\n",
    "        # update minicourt obj pos using calculated distances\n",
    "        ## obj is right(+) or left(-) of kp\n",
    "        if object_position[0] >= closest_keypoint[0]:\n",
    "            minicourt_obj_pos[0] = minicourt_obj_pos[0] + minicourt_dist_obj_to_kp_x_pixels\n",
    "        else:\n",
    "            minicourt_obj_pos[0] = minicourt_obj_pos[0] - minicourt_dist_obj_to_kp_x_pixels\n",
    "        ## obj is above(-) or below(+) kp\n",
    "        if object_position[1] <= closest_keypoint[1]:\n",
    "            minicourt_obj_pos[1] = minicourt_obj_pos[1] - minicourt_dist_obj_to_kp_y_pixels\n",
    "        else:\n",
    "            minicourt_obj_pos[1] = minicourt_obj_pos[1] + minicourt_dist_obj_to_kp_y_pixels\n",
    "\n",
    "        return tuple(minicourt_obj_pos)\n",
    "\n",
    "    def convert_bboxes_to_minicourt_coordinates(self, player_bboxes, ball_bboxes, original_court_keypoints):\n",
    "\n",
    "        print(\"Total frames:\", len(player_bboxes))\n",
    "        for i, frame_bbox in enumerate(player_bboxes):\n",
    "            print(f\"Frame {i} player bboxes:\", frame_bbox)\n",
    "            print(f\"Frame {i} player bbox keys:\", frame_bbox.keys() if frame_bbox else \"No bboxes\")\n",
    "\n",
    "\n",
    "        player_ids = list(player_bboxes[0].keys()) if player_bboxes else []\n",
    "        print(player_ids)\n",
    "        \n",
    "        player_heights = {\n",
    "            player_ids[0]: PLAYER_1_HEIGHT,\n",
    "            player_ids[1]: PLAYER_2_HEIGHT\n",
    "        } if player_ids else {}\n",
    "\n",
    "        output_player_bboxes = []\n",
    "        output_ball_bboxes = []\n",
    "\n",
    "        for frame_num, player_bbox in enumerate(player_bboxes):\n",
    "            # Skip if there are no player detections for this frame\n",
    "            if not player_bbox:\n",
    "                print(f\"Skipping frame {frame_num}: No player detections available.\")\n",
    "                output_player_bboxes.append({})\n",
    "                output_ball_bboxes.append({})\n",
    "                continue\n",
    "\n",
    "            ball_bbox = ball_bboxes[frame_num][1]\n",
    "            ball_pos = get_center_of_bbox(ball_bbox)\n",
    "\n",
    "            # Skip if there are no player detections for this frame\n",
    "            if not player_bbox:\n",
    "                print(f\"Skipping frame {frame_num}: No player detections.\")\n",
    "                continue\n",
    "\n",
    "            # Ensure the player_bbox is not empty before calling min()\n",
    "            if player_bbox:\n",
    "                closest_player_id_to_ball = min(player_bbox.keys(),\n",
    "                                                key=lambda x: euclidean_distance(ball_pos, get_center_of_bbox(player_bbox[x])))\n",
    "            else:\n",
    "                print(f\"No player bounding boxes for frame {frame_num}.\")\n",
    "                continue  # Skip this frame if no player bounding boxes\n",
    "\n",
    "            # kp_indices to consider for closest keypoints\n",
    "            kp_indices = [i for i in range(4, 19)]\n",
    "\n",
    "            # Each frame is represented as a dict in the output list\n",
    "            output_player_bboxes_dict = {}\n",
    "            for player_id, bbox in player_bbox.items():\n",
    "                foot_pos = get_foot_position(bbox)\n",
    "\n",
    "                # Find the closest keypoint to the player's foot\n",
    "                closest_kp_to_player_idx = get_closest_keypoint_index(foot_pos, original_court_keypoints, kp_indices)\n",
    "                closest_kp_to_player = (original_court_keypoints[closest_kp_to_player_idx*2],\n",
    "                                        original_court_keypoints[closest_kp_to_player_idx*2+1])\n",
    "\n",
    "                # Find the maximum player height in pixels over the recent frames\n",
    "                frame_idx_min = max(0, frame_num-20)\n",
    "                frame_idx_max = min(len(player_bboxes), frame_num+50)\n",
    "                player_bboxes_height_in_pixels = [\n",
    "                    get_bbox_height(player_bboxes[i].get(player_id, [0, 0, 0, 0]))\n",
    "                    for i in range(frame_idx_min, frame_idx_max)\n",
    "                ]\n",
    "                max_player_height_in_pixels = max(player_bboxes_height_in_pixels)\n",
    "\n",
    "                # Convert the closest keypoint to minicourt coordinates\n",
    "                minicourt_player_pos = self.get_minicourt_coordinates(foot_pos,\n",
    "                                                                    closest_kp_to_player,\n",
    "                                                                    closest_kp_to_player_idx,\n",
    "                                                                    max_player_height_in_pixels,\n",
    "                                                                    player_heights[player_id])\n",
    "\n",
    "                output_player_bboxes_dict[player_id] = minicourt_player_pos\n",
    "\n",
    "                # If this player is the closest to the ball, convert the ball position\n",
    "                if closest_player_id_to_ball == player_id:\n",
    "                    closest_kp_to_ball_idx = get_closest_keypoint_index(ball_pos,\n",
    "                                                                    original_court_keypoints,\n",
    "                                                                    kp_indices)\n",
    "                    closest_kp_to_ball = (original_court_keypoints[closest_kp_to_ball_idx*2],\n",
    "                                        original_court_keypoints[closest_kp_to_ball_idx*2+1])\n",
    "\n",
    "                    minicourt_ball_pos = self.get_minicourt_coordinates(ball_pos,\n",
    "                                                                        closest_kp_to_ball,\n",
    "                                                                        closest_kp_to_ball_idx,\n",
    "                                                                        max_player_height_in_pixels,\n",
    "                                                                        player_heights[player_id])\n",
    "                    output_ball_bboxes.append({1: minicourt_ball_pos})\n",
    "\n",
    "            output_player_bboxes.append(output_player_bboxes_dict)\n",
    "\n",
    "        return output_player_bboxes, output_ball_bboxes\n",
    "    \n",
    "    def draw_points_on_minicourt(self, frames, positions, color=(255,0,0)):\n",
    "        for frame_num, frame in enumerate(frames):\n",
    "            for i, pos in positions[frame_num].items():\n",
    "                x, y = pos\n",
    "                x = int(x)\n",
    "                y = int(y)\n",
    "                cv2.circle(frame, (x,y), 5, color, -1)\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BallTracker:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def interpolate_ball_positions(self, ball_detections):\n",
    "        \"\"\"detects ball in every frame by interpolating the missing bbox coordinates\n",
    "        Returns:\n",
    "            dict: imputed ball bbox coords\n",
    "        \"\"\"\n",
    "        ball_positions = [x.get(1, []) for x in ball_detections]\n",
    "\n",
    "        # convert list to pandas df to interpolate the missing vals\n",
    "        df_ball_positions = pd.DataFrame(ball_positions, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "        \n",
    "        # interpolate missing vals\n",
    "        df_ball_positions = df_ball_positions.interpolate(method='polynomial', order=3)\n",
    "        \n",
    "        # since default direction is forward, we need to fill the 1st row\n",
    "        df_ball_positions = df_ball_positions.bfill()\n",
    "        \n",
    "        ball_positions = [{1:x} for x in df_ball_positions.to_numpy().tolist()]\n",
    "        \n",
    "        return ball_positions\n",
    "\n",
    "    def detect_frames(self, frames, read_from_stub=False, stub_path=None):\n",
    "        \"\"\"detects the ball bbox coords of each frame\n",
    "        Returns:\n",
    "            list of dicts: [{id1: [bbox_coords]}, ...,\n",
    "                            {id1: [bbox_coords]}]\n",
    "        \"\"\"\n",
    "        ball_detections = []\n",
    "\n",
    "        # load saved ball detections\n",
    "        if read_from_stub and stub_path is not None:\n",
    "            with open(stub_path, 'rb') as f:\n",
    "                ball_detections = pickle.load(f)\n",
    "            return ball_detections\n",
    "            \n",
    "        for frame in frames:\n",
    "            ball_dict = self.detect_frame(frame)\n",
    "            ball_detections.append(ball_dict)\n",
    "\n",
    "        if stub_path is not None:\n",
    "            with open(stub_path, 'wb') as f:\n",
    "                pickle.dump(ball_detections, f)\n",
    "\n",
    "        return ball_detections\n",
    "\n",
    "    def get_ball_hit_frames(self, ball_detections):\n",
    "        '''outputs the indices of the frames where the ball has been hit'''\n",
    "        ball_positions = [x.get(1, []) for x in ball_detections]\n",
    "\n",
    "        # convert list to pandas df to interpolate the missing vals\n",
    "        df_ball_positions = pd.DataFrame(ball_positions, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "        # get smooth detections in all frames\n",
    "        df_ball_positions['mid_y'] = (df_ball_positions['y1'] + df_ball_positions['y2']) / 2\n",
    "        # reduce the effect of outliers\n",
    "        df_ball_positions['mid_y_rolling_mean'] = df_ball_positions['mid_y'].rolling(window=5, min_periods=1, center=False).mean()\n",
    "        df_ball_positions['delta_y'] = df_ball_positions['mid_y_rolling_mean'].diff()  # subtracts 2 consecutive rows from each other\n",
    "\n",
    "        # init a new col to track frames where ball is hit\n",
    "        df_ball_positions['ball_hit'] = 0\n",
    "        \n",
    "        # atleast for 25 frames ball moves in one direction (increasing or decreasing)\n",
    "        min_change_frames_for_hit = 25\n",
    "        for i in range(1, len(df_ball_positions) - int(min_change_frames_for_hit*1.2)):\n",
    "            negative_pos_change = df_ball_positions['delta_y'].iloc[i] > 0 and df_ball_positions['delta_y'].iloc[i+1] < 0\n",
    "            positive_pos_change = df_ball_positions['delta_y'].iloc[i] < 0 and df_ball_positions['delta_y'].iloc[i+1] > 0\n",
    "\n",
    "            # count pos changes in one direction\n",
    "            if negative_pos_change or positive_pos_change:\n",
    "                pos_change_count = 0\n",
    "                for nxt_frame_idx in range(i+1, i + int(min_change_frames_for_hit * 1.2) + 1):\n",
    "                    negative_pos_change_nxt_frame = df_ball_positions['delta_y'].iloc[i] > 0 and df_ball_positions['delta_y'].iloc[nxt_frame_idx] < 0\n",
    "                    positive_pos_change_nxt_frame = df_ball_positions['delta_y'].iloc[i] < 0 and df_ball_positions['delta_y'].iloc[nxt_frame_idx] > 0\n",
    "\n",
    "                    if negative_pos_change and negative_pos_change_nxt_frame:\n",
    "                        pos_change_count += 1\n",
    "                    elif positive_pos_change and positive_pos_change_nxt_frame:\n",
    "                        pos_change_count += 1\n",
    "\n",
    "                if pos_change_count > min_change_frames_for_hit - 1:\n",
    "                    df_ball_positions.loc[i, 'ball_hit'] = 1\n",
    "\n",
    "        ball_hit_frames_idx = df_ball_positions[df_ball_positions['ball_hit'] == 1].index.tolist()\n",
    "        return ball_hit_frames_idx\n",
    "\n",
    "    def detect_frame(self, frame):\n",
    "        \"\"\" detects a ball class object and finds out its bbox coords\n",
    "        Returns:\n",
    "            dict: {id: [bbox coords]}\n",
    "        \"\"\"\n",
    "        result = self.model.predict(frame, conf=0.15)[0]\n",
    "        \n",
    "        ball_dict = {}\n",
    "        for box in result.boxes:\n",
    "            bbox_coords = box.xyxy.tolist()[0]\n",
    "            ball_dict[1] = bbox_coords\n",
    "        \n",
    "        return ball_dict\n",
    "\n",
    "    def draw_bboxes(self, video_frames, ball_detections):\n",
    "        '''draws a bbox around the ball'''\n",
    "        output_video_frames = []\n",
    "        for frame, ball_dict in zip(video_frames, ball_detections):\n",
    "            # draw bboxes\n",
    "            for tracking_id, bbox_coords in ball_dict.items():\n",
    "                x1, y1, x2, y2 = bbox_coords\n",
    "                # text\n",
    "                # cv2.putText(frame, f\"Ball ID: {tracking_id}\", (int(x1), int(y1)-10), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,255,255), 2)\n",
    "                # bbox\n",
    "                if any(math.isnan(coord) for coord in [x1, y1, x2, y2]):\n",
    "                    print(f\"Invalid bounding box coordinates: {x1}, {y1}, {x2}, {y2}\")\n",
    "                    continue  # Skip this frame or bounding box\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,255,255), 2)\n",
    "            output_video_frames.append(frame)\n",
    "        \n",
    "        return output_video_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerTracker:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def choose_and_filter_players(self, court_keypoints, player_detections):\n",
    "        \"\"\"filters the 2 tennis players\n",
    "        Returns:\n",
    "            list: [{tracking_id_1: bbox_coords},\n",
    "                    {tracking_id_2: bbox_coords}]\n",
    "        \"\"\"\n",
    "        player_detections_first_frame = player_detections[0]\n",
    "        chosen_two_players = self.choose_players(court_keypoints, player_detections_first_frame)\n",
    "        filtered_player_detections = []\n",
    "        for player_dict in player_detections:\n",
    "            # filter only the 2 tennis players in each frame\n",
    "            filtered_player_dict = {tracking_id: bbox_coords for tracking_id, bbox_coords in player_dict.items() if tracking_id in chosen_two_players}\n",
    "            filtered_player_detections.append(filtered_player_dict)\n",
    "        return filtered_player_detections\n",
    "    \n",
    "    def choose_players(self, court_keypoints, player_dict):\n",
    "        \"\"\"finds the 2 tennis players among all people in the frame\n",
    "        Returns:\n",
    "            list: tracking_ids of the 2 nearest people to the court\n",
    "        \"\"\"\n",
    "        distances = []\n",
    "        for tracking_id, bbox_coords in player_dict.items():\n",
    "            player_center = get_center_of_bbox(bbox_coords)\n",
    "            min_dist = float('inf')\n",
    "            cumulative_dist = 0\n",
    "            for i in range(0, len(court_keypoints), 2):\n",
    "                court_keypoint = (court_keypoints[i], court_keypoints[i+1])\n",
    "                curr_dist = euclidean_distance(player_center, court_keypoint)\n",
    "                cumulative_dist += curr_dist\n",
    "                #if curr_dist <= min_dist:\n",
    "                    # shortest distance for a player to a court_keypoint among all other court_keypoints\n",
    "                #   min_dist = curr_dist\n",
    "            distances.append((tracking_id, cumulative_dist))\n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        # choose top 2 shortest distances\n",
    "        chosen_players = [1, 2]\n",
    "        print(chosen_players)\n",
    "        return chosen_players\n",
    "\n",
    "    def detect_frames(self, frames, read_from_stub=False, stub_path=None):\n",
    "        player_detections = []\n",
    "\n",
    "        # load saved player detections\n",
    "        if read_from_stub and stub_path is not None:\n",
    "            with open(stub_path, 'rb') as f:\n",
    "                player_detections = pickle.load(f)\n",
    "            return player_detections\n",
    "        \n",
    "        print('frame detections len: ', len(frames))\n",
    "        for frame in frames:\n",
    "\n",
    "            player_dict = self.detect_frame(frame)\n",
    "            player_detections.append(player_dict)\n",
    "\n",
    "        if stub_path is not None:\n",
    "            with open(stub_path, 'wb') as f:\n",
    "                pickle.dump(player_detections, f)\n",
    "\n",
    "        print('player detections len: ', len(player_detections))\n",
    "        return player_detections\n",
    "\n",
    "    def detect_frame(self, frame):\n",
    "        \"\"\" tracks each person class object using a unique tracking id and finds out their respective bbox coords\n",
    "        Returns:\n",
    "            dict: {tracking_id of person 1: [bbox coords], ..., \n",
    "                    tracking_id of person n: [bbox_coords]}\n",
    "        \"\"\"\n",
    "        results = self.model.track(frame, persist=True)[0]\n",
    "        id_name_dict = results.names  # {id1: obj1, ..., id2: obj2}\n",
    "        \n",
    "        player_dict = {}\n",
    "        \"\"\"\n",
    "        Results for Frame 1:\n",
    "        {\n",
    "            boxes: [\n",
    "                {\n",
    "                    'id': tensor([3]),               # Tracking ID for this object\n",
    "                    'cls': tensor([0]),               # Class ID (e.g., 0 for \"person\")\n",
    "                    'xyxy': tensor([[100, 200, 300, 400]]),  # Bounding box coordinates\n",
    "                    'confidence': tensor([0.95])      # Confidence score\n",
    "                },\n",
    "                {\n",
    "                    'id': tensor([4]),\n",
    "                    'cls': tensor([0]),\n",
    "                    'xyxy': tensor([[150, 250, 350, 450]]),\n",
    "                    'confidence': tensor([0.92])\n",
    "                }\n",
    "            ],\n",
    "            masks: None,  # Only present if segmentation model is used\n",
    "            names: {0: \"person\", 1: \"car\"},  # Dictionary mapping class IDs to names\n",
    "        }\n",
    "        \"\"\"\n",
    "        for box in results.boxes:\n",
    "            # convert tracking_id to int\n",
    "            #print(box)\n",
    "            tracking_id = int(box.id.tolist()[0])\n",
    "            # xyxy: [x1, y1, x2, y2]\n",
    "                # (x1, y1) - top-left\n",
    "                # (x2, y2) - bottom-right\n",
    "            bbox_coords = box.xyxy.tolist()[0]\n",
    "            obj_cls_id = box.cls.tolist()[0]\n",
    "            obj_cls_name = id_name_dict[obj_cls_id]\n",
    "            # only consider boxes with people\n",
    "            if obj_cls_name == \"person\":\n",
    "                player_dict[tracking_id] = bbox_coords\n",
    "        \n",
    "        return player_dict\n",
    "\n",
    "    def draw_bboxes(self, video_frames, player_detections):\n",
    "        '''draws bbox around all person class objects in the video'''\n",
    "        output_video_frames = []\n",
    "        for frame, player_dict in zip(video_frames, player_detections):\n",
    "            # draw bboxes\n",
    "            for tracking_id, bbox_coords in player_dict.items():\n",
    "                x1, y1, x2, y2 = bbox_coords\n",
    "                # text\n",
    "                cv2.putText(frame, f\"Player ID: {tracking_id}\", (int(x1), int(y1)-10), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255,0,0), 2)\n",
    "                # bbox\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255,0,0), 2)\n",
    "            output_video_frames.append(frame)\n",
    "        \n",
    "        return output_video_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_of_bbox(bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    center_x = int((x1 + x2) / 2)\n",
    "    center_y = int((y1 + y2) / 2)\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    return ((p2[0]-p1[0])**2 + (p2[1]-p1[1])**2)**0.5\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return ((p1[0]+p2[0])/2, (p1[1]+p2[1])/2)\n",
    "\n",
    "def get_foot_position(bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    return ((x1 + x2) / 2, y2)\n",
    "\n",
    "def get_closest_keypoint_index(point, keypoints, keypoint_indices):\n",
    "    closest_kp_dist = float('inf')\n",
    "    closest_kp_idx = keypoint_indices[0]\n",
    "    for kp_idx in keypoint_indices:\n",
    "        kp = keypoints[kp_idx*2], keypoints[kp_idx*2+1]\n",
    "        kp_dist = euclidean_distance(point, kp)\n",
    "        if kp_dist < closest_kp_dist:\n",
    "            closest_kp_dist = kp_dist\n",
    "            closest_kp_idx = kp_idx\n",
    "    return closest_kp_idx\n",
    "\n",
    "def get_bbox_height(bbox):\n",
    "    return bbox[3] - bbox[1]\n",
    "\n",
    "def measure_xy_distance(p1, p2):\n",
    "    return abs(p1[0] - p2[0]), abs(p1[1] - p2[1])\n",
    "\n",
    "def get_center_of_bbox(bbox):\n",
    "    if any(map(math.isnan, bbox)):\n",
    "        print(f\"Invalid bbox coordinates: {bbox}\")\n",
    "        return (0,0) # Or some default value\n",
    "    return (int((bbox[0]+bbox[2])/2), int((bbox[1]+bbox[3])/2))\n",
    "\n",
    "def keypoints_to_idx(keypoints, idx):\n",
    "    return (keypoints[2*idx], keypoints[2*idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pixel_distance_to_meters(pixel_distance, reference_height_in_pixels, reference_height_in_meters):\n",
    "    return pixel_distance * (reference_height_in_meters / reference_height_in_pixels)\n",
    "\n",
    "def convert_meters_to_pixel_distance(meters, reference_height_in_meters, reference_height_in_pixels):\n",
    "    return meters * (reference_height_in_pixels / reference_height_in_meters)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_player_stats(output_video_frames, player_stats):\n",
    "    for idx, row in player_stats.iterrows():\n",
    "        player_1_shot_speed = row['player_1_curr_shot_speed']\n",
    "        player_2_shot_speed = row['player_2_curr_shot_speed']\n",
    "        \n",
    "        player_1_speed = row['player_1_curr_speed']\n",
    "        player_2_speed = row['player_2_curr_speed']\n",
    "\n",
    "        player_1_avg_shot_speed = row['player_1_avg_shot_speed']\n",
    "        player_2_avg_shot_speed = row['player_2_avg_shot_speed']\n",
    "\n",
    "        player_1_avg_speed = row['player_1_avg_speed']\n",
    "        player_2_avg_speed = row['player_2_avg_speed']\n",
    "\n",
    "        frame = output_video_frames[idx]  # extracts curr frame\n",
    "\n",
    "        # transparent stats box\n",
    "        shapes = np.zeros_like(frame, np.uint8)  # creates a blank img same as frame dim\n",
    "        # draw overlay rectangle on blank frame\n",
    "        width = 350\n",
    "        height = 230\n",
    "        start_x = frame.shape[1] - 400  # frame.shape -> (b * l) -> (1080 * 1920)\n",
    "        start_y = frame.shape[0] - 500\n",
    "        end_x = start_x + width\n",
    "        end_y = start_y + height\n",
    "\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (start_x, start_y), (end_x, end_y), (0,0,0), -1)\n",
    "        alpha = 0.5\n",
    "        cv2.addWeighted(overlay, alpha, frame, 1-alpha, 0, frame)\n",
    "        output_video_frames[idx] = frame\n",
    "\n",
    "        # add text to overlay rectangle\n",
    "        text = \"    Player 1    Player 2\"\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               text,\n",
    "                                               (start_x+90, start_y+30),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.6,\n",
    "                                               (255,255,255),\n",
    "                                               2)\n",
    "\n",
    "        text = \"Shot Speed:\"\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               text,\n",
    "                                               (start_x+10, start_y+80), \n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                               0.45, \n",
    "                                               (0,255,255),\n",
    "                                               2)\n",
    "        player_1_text = f\"{player_1_shot_speed:.1f} km/h\"\n",
    "        player_2_text = f\"{player_2_shot_speed:.1f} km/h\"\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               player_1_text, \n",
    "                                               (start_x + 130, start_y + 80),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.45,\n",
    "                                               (0, 255, 255),\n",
    "                                               2)\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               player_2_text,\n",
    "                                               (start_x + 130 + 120, start_y + 80),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.45,\n",
    "                                               (0, 255, 255),\n",
    "                                               2)\n",
    "        \n",
    "        \n",
    "\n",
    "        text = \"Player Speed:\"\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               text,\n",
    "                                               (start_x+10, start_y+120),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.45,\n",
    "                                               (255,255,255),\n",
    "                                               2)\n",
    "        player_1_text = f\"{player_1_speed:.1f} km/h\"\n",
    "        player_2_text = f\"{player_2_speed:.1f} km/h\"\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               player_1_text, \n",
    "                                               (start_x + 130, start_y + 120),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.45,\n",
    "                                               (255, 255, 255),\n",
    "                                               2)\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               player_2_text,\n",
    "                                               (start_x + 130 + 120, start_y + 120),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.45,\n",
    "                                               (255, 255, 255),\n",
    "                                               2)\n",
    "\n",
    "\n",
    "        text = \"Avg Sh Speed:\"\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx], text, (start_x+10, start_y+160), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,255,255), 2)\n",
    "        player_1_text = f\"{player_1_avg_shot_speed:.1f} km/h\"\n",
    "        player_2_text = f\"{player_2_avg_shot_speed:.1f} km/h\"\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               player_1_text, \n",
    "                                               (start_x + 130, start_y + 160),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.45,\n",
    "                                               (0, 255, 255),\n",
    "                                               2)\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               player_2_text,\n",
    "                                               (start_x + 130 + 120, start_y + 160),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.45,\n",
    "                                               (0, 255, 255),\n",
    "                                               2)\n",
    "       \n",
    "        text = \"Avg Pl Speed:\"\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx], text, (start_x+10, start_y+200), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 2)\n",
    "        player_1_text = f\"{player_1_avg_speed:.1f} km/h\"\n",
    "        player_2_text = f\"{player_2_avg_speed:.1f} km/h\"\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               player_1_text, \n",
    "                                               (start_x + 130, start_y + 200),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.45,\n",
    "                                               (255, 255, 255),\n",
    "                                               2)\n",
    "        output_video_frames[idx] = cv2.putText(output_video_frames[idx],\n",
    "                                               player_2_text,\n",
    "                                               (start_x + 130 + 120, start_y + 200),\n",
    "                                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                               0.45,\n",
    "                                               (255, 255, 255),\n",
    "                                               2)\n",
    "    \n",
    "    return output_video_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(video_path):\n",
    "    # read video from a file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file\")\n",
    "    frames = []\n",
    "    while True:\n",
    "        # read frame by frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(output_video_frames, output_video_path):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "    out = cv2.VideoWriter(output_video_path,\n",
    "                          fourcc,\n",
    "                          24,\n",
    "                          (output_video_frames[0].shape[1], output_video_frames[0].shape[0]))\n",
    "    for frame in output_video_frames:\n",
    "        out.write(frame)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # read video\n",
    "    input_video_path = \"S:/Uni_stuff/Semester_7/Ilmu_Data_2/Proyek/Tennis-Analysis-YOLO-PyTorch-main/input_videos/short.mp4\"\n",
    "    video_frames = read_video(input_video_path)\n",
    "\n",
    "    # detect players and ball\n",
    "    player_tracker = PlayerTracker(model_path=\"yolov8x\")\n",
    "    ball_tracker = BallTracker(model_path=\"S:/Uni_stuff/Semester_7/Ilmu_Data_2/Proyek/Tennis-Analysis-YOLO-PyTorch-main/models/best.pt\")\n",
    "\n",
    "    player_detections = player_tracker.detect_frames(video_frames,\n",
    "                                                     read_from_stub=False,\n",
    "                                                     stub_path=\"S:/Uni_stuff/Semester_7/Ilmu_Data_2/Proyek/Tennis-Analysis-YOLO-PyTorch-main/tracker_stubs/player_detections_short.pkl\")\n",
    "    print('-'*30)\n",
    "    print('Player detections done')\n",
    "\n",
    "    ball_detections = ball_tracker.detect_frames(video_frames,\n",
    "                                                read_from_stub=False,\n",
    "                                                stub_path=\"S:/Uni_stuff/Semester_7/Ilmu_Data_2/Proyek/Tennis-Analysis-YOLO-PyTorch-main/tracker_stubs/ball_detections_short.pkl\")\n",
    "    \n",
    "    ball_detections = ball_tracker.interpolate_ball_positions(ball_detections)\n",
    "    print('-'*30)\n",
    "    print('Ball detections done')\n",
    "    \n",
    "    # court line detector model\n",
    "    court_model_path = \"S:/Uni_stuff/Semester_7/Ilmu_Data_2/Proyek/Tennis-Analysis-YOLO-PyTorch-main/models/keypoints_model.pth\"\n",
    "    court_line_detector = CourtLineDetector(court_model_path)\n",
    "    court_keypoints = court_line_detector.predict(video_frames[0])\n",
    "    print('-'*30)\n",
    "    print('Keypoints prediction done')\n",
    "\n",
    "    # choose tennis players\n",
    "    player_detections = player_tracker.choose_and_filter_players(court_keypoints, player_detections)\n",
    "\n",
    "    # Mini court\n",
    "    minicourt = MiniCourt(video_frames[0])\n",
    "    ## convert court positions to minicourt positions\n",
    "    minicourt_player_detections, minicourt_ball_detections = minicourt.convert_bboxes_to_minicourt_coordinates(player_detections, ball_detections, court_keypoints)\n",
    "    print('-'*30)\n",
    "    print('Conversion to minicourt coordinates done')\n",
    "    \n",
    "    player_stats = [{\n",
    "            'frame_num': 0,\n",
    "            'player_1_number_of_shots': 0,\n",
    "            'player_1_cumulative_shot_speed': 0,\n",
    "            'player_1_curr_shot_speed': 0,\n",
    "            'player_1_cumulative_speed': 0,\n",
    "            'player_1_curr_speed': 0,\n",
    "\n",
    "            'player_2_number_of_shots': 0,\n",
    "            'player_2_cumulative_shot_speed': 0,\n",
    "            'player_2_curr_shot_speed': 0,\n",
    "            'player_2_cumulative_speed': 0,\n",
    "            'player_2_curr_speed': 0\n",
    "    }]\n",
    "\n",
    "    # detect ball hits\n",
    "    ball_hit_frames = ball_tracker.get_ball_hit_frames(ball_detections)\n",
    "\n",
    "    # Cache for the most recent valid detections for each player and the ball\n",
    "    recent_valid_player_positions = {}\n",
    "    recent_valid_ball_detections = {}\n",
    "\n",
    "    for ball_hit_idx in range(len(ball_hit_frames) - 1):\n",
    "        start_frame = ball_hit_frames[ball_hit_idx]\n",
    "        end_frame = ball_hit_frames[ball_hit_idx + 1]\n",
    "\n",
    "        print(f\"Processing ball hit from frame {start_frame} to {end_frame}\")\n",
    "\n",
    "        # Update and retrieve current player and ball positions\n",
    "        current_player_positions = minicourt_player_detections[start_frame] if (\n",
    "            start_frame < len(minicourt_player_detections) and minicourt_player_detections[start_frame]\n",
    "        ) else recent_valid_player_positions\n",
    "\n",
    "        current_ball_detection = minicourt_ball_detections[start_frame] if (\n",
    "            start_frame < len(minicourt_ball_detections) and minicourt_ball_detections[start_frame]\n",
    "        ) else recent_valid_ball_detections\n",
    "\n",
    "        # Ensure fallback positions are available\n",
    "        if not current_player_positions or not current_ball_detection:\n",
    "            print(f\"Skipping frame {start_frame}: Missing player or ball detections and no valid fallback.\")\n",
    "            continue\n",
    "\n",
    "        # Update recent valid detections\n",
    "        recent_valid_player_positions = current_player_positions\n",
    "        recent_valid_ball_detections = current_ball_detection\n",
    "\n",
    "        try:\n",
    "            # Determine the player who hit the ball\n",
    "            ball_hit_player_id = min(\n",
    "                current_player_positions.keys(),\n",
    "                key=lambda player_id: euclidean_distance(\n",
    "                    current_player_positions[player_id],\n",
    "                    current_ball_detection[1]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            print(f\"Ball hit by player {ball_hit_player_id}\")\n",
    "\n",
    "            opp_player_id = 1 if ball_hit_player_id == 2 else 2\n",
    "\n",
    "            # Handle opponent player detection\n",
    "            if opp_player_id not in current_player_positions:\n",
    "                print(f\"Opponent player {opp_player_id} not detected in frame {start_frame}. Using most recent valid position.\")\n",
    "                opp_player_start = recent_valid_player_positions.get(opp_player_id)\n",
    "            else:\n",
    "                opp_player_start = current_player_positions[opp_player_id]\n",
    "\n",
    "            if end_frame < len(minicourt_player_detections) and opp_player_id in minicourt_player_detections[end_frame]:\n",
    "                opp_player_end = minicourt_player_detections[end_frame][opp_player_id]\n",
    "            else:\n",
    "                opp_player_end = recent_valid_player_positions.get(opp_player_id)\n",
    "\n",
    "            # Ensure fallback data is available\n",
    "            if not opp_player_start or not opp_player_end:\n",
    "                print(f\"Skipping frame {start_frame}: Missing opponent player detection even after using most recent fallback.\")\n",
    "                continue\n",
    "\n",
    "            # Calculate ball hit time\n",
    "            ball_hit_time_taken_s = (end_frame - start_frame) / 24  # 24 fps\n",
    "\n",
    "            # Calculate ball travel distance and speed\n",
    "            ball_hit_dist_covered_pixels = euclidean_distance(\n",
    "                minicourt_ball_detections[start_frame][1],\n",
    "                minicourt_ball_detections[end_frame][1]\n",
    "            )\n",
    "            ball_hit_dist_covered_meters = convert_pixel_distance_to_meters(\n",
    "                ball_hit_dist_covered_pixels,\n",
    "                minicourt.get_length_of_minicourt(),\n",
    "                COURT_LENGTH\n",
    "            ) * 2.2\n",
    "            ball_hit_speed = ball_hit_dist_covered_meters / ball_hit_time_taken_s * 3.6  # km/h\n",
    "\n",
    "            # Calculate opposing player's speed\n",
    "            opp_player_dist_covered_pixels = euclidean_distance(\n",
    "                opp_player_start,\n",
    "                opp_player_end\n",
    "            )\n",
    "            opp_player_dist_covered_meters = convert_pixel_distance_to_meters(\n",
    "                opp_player_dist_covered_pixels,\n",
    "                minicourt.get_width_of_minicourt(),\n",
    "                DOUBLES_BASELINE_WIDTH\n",
    "            ) * 2.2\n",
    "            opp_player_speed = opp_player_dist_covered_meters / ball_hit_time_taken_s * 3.6\n",
    "\n",
    "            # Update player statistics\n",
    "            curr_player_stats = deepcopy(player_stats[-1])\n",
    "            curr_player_stats['frame_num'] = start_frame\n",
    "            curr_player_stats[f\"player_{ball_hit_player_id}_number_of_shots\"] += 1\n",
    "            curr_player_stats[f\"player_{ball_hit_player_id}_cumulative_shot_speed\"] += ball_hit_speed\n",
    "            curr_player_stats[f\"player_{ball_hit_player_id}_curr_shot_speed\"] = ball_hit_speed\n",
    "            curr_player_stats[f\"player_{opp_player_id}_cumulative_speed\"] += opp_player_speed\n",
    "            curr_player_stats[f\"player_{opp_player_id}_curr_speed\"] = opp_player_speed\n",
    "\n",
    "            player_stats.append(curr_player_stats)\n",
    "            print(f\"Updated player stats for frame {start_frame}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing ball hit at frames {start_frame}-{end_frame}: {e}\")\n",
    "\n",
    "    \n",
    "    # player stats df\n",
    "    df_player_stats = pd.DataFrame(player_stats)\n",
    "    df_frames = pd.DataFrame({'frame_num': list(range(len(video_frames)))})\n",
    "    df_player_stats = pd.merge(df_frames, df_player_stats, on='frame_num', how='left')\n",
    "    df_player_stats = df_player_stats.ffill()\n",
    "    print('-'*30)\n",
    "    print('Player stats done')\n",
    "\n",
    "    # average hit speed using cumulative hit speed\n",
    "    df_player_stats['player_1_avg_shot_speed'] = df_player_stats['player_1_cumulative_shot_speed'] / df_player_stats['player_1_number_of_shots']\n",
    "    df_player_stats['player_2_avg_shot_speed'] = df_player_stats['player_2_cumulative_shot_speed'] / df_player_stats['player_2_number_of_shots']\n",
    "    df_player_stats['player_1_avg_speed'] = df_player_stats['player_1_cumulative_speed'] / df_player_stats['player_1_number_of_shots']\n",
    "    df_player_stats['player_2_avg_speed'] = df_player_stats['player_2_cumulative_speed'] / df_player_stats['player_2_number_of_shots']\n",
    "\n",
    "    # Draw output\n",
    "    ## player bbox\n",
    "    output_video_frames = player_tracker.draw_bboxes(video_frames, player_detections)\n",
    "\n",
    "    ## draw ball bbox\n",
    "    output_video_frames = ball_tracker.draw_bboxes(video_frames, ball_detections)\n",
    "\n",
    "    ## court keypoints\n",
    "    output_video_frames = court_line_detector.draw_keypoints_on_video(output_video_frames, court_keypoints)\n",
    "\n",
    "    ## minicourt\n",
    "    output_video_frames = minicourt.draw_minicourt(output_video_frames)\n",
    "    output_video_frames = minicourt.draw_points_on_minicourt(output_video_frames,\n",
    "                                                             minicourt_player_detections)\n",
    "    output_video_frames = minicourt.draw_points_on_minicourt(output_video_frames,\n",
    "                                                             minicourt_ball_detections,\n",
    "                                                             color=(0,255,255))\n",
    "    print('-'*30)\n",
    "    print('Minicourt done')\n",
    "\n",
    "    ## player stats\n",
    "    output_video_frames = draw_player_stats(output_video_frames, df_player_stats)\n",
    "    ## frame number\n",
    "    for i, frame in enumerate(output_video_frames):\n",
    "        cv2.putText(frame, f\"Frame: {i+1}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "    # save video\n",
    "    save_video(output_video_frames, \"S:/Uni_stuff/Semester_7/Ilmu_Data_2/Proyek/Tennis-Analysis-YOLO-PyTorch-main/output_videos/short_output.avi\")\n",
    "    print('-'*30)\n",
    "    print('Video saved successfully')\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame detections len:  137\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 617.0ms\n",
      "Speed: 3.0ms preprocess, 617.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 683.4ms\n",
      "Speed: 3.0ms preprocess, 683.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 878.0ms\n",
      "Speed: 2.0ms preprocess, 878.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 737.0ms\n",
      "Speed: 2.0ms preprocess, 737.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 695.0ms\n",
      "Speed: 2.0ms preprocess, 695.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 689.0ms\n",
      "Speed: 4.0ms preprocess, 689.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 643.0ms\n",
      "Speed: 2.0ms preprocess, 643.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 648.0ms\n",
      "Speed: 2.0ms preprocess, 648.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 737.0ms\n",
      "Speed: 2.0ms preprocess, 737.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 805.0ms\n",
      "Speed: 2.0ms preprocess, 805.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 649.0ms\n",
      "Speed: 2.0ms preprocess, 649.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 644.0ms\n",
      "Speed: 2.0ms preprocess, 644.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 623.0ms\n",
      "Speed: 2.0ms preprocess, 623.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 616.0ms\n",
      "Speed: 2.0ms preprocess, 616.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 664.0ms\n",
      "Speed: 2.0ms preprocess, 664.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 612.0ms\n",
      "Speed: 2.0ms preprocess, 612.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 618.0ms\n",
      "Speed: 2.0ms preprocess, 618.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 625.0ms\n",
      "Speed: 2.0ms preprocess, 625.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 621.0ms\n",
      "Speed: 2.0ms preprocess, 621.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 628.0ms\n",
      "Speed: 3.0ms preprocess, 628.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 615.5ms\n",
      "Speed: 2.0ms preprocess, 615.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 628.0ms\n",
      "Speed: 2.0ms preprocess, 628.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 653.0ms\n",
      "Speed: 3.0ms preprocess, 653.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 685.0ms\n",
      "Speed: 2.0ms preprocess, 685.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 619.0ms\n",
      "Speed: 3.0ms preprocess, 619.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 613.0ms\n",
      "Speed: 1.0ms preprocess, 613.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 598.0ms\n",
      "Speed: 2.0ms preprocess, 598.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 605.0ms\n",
      "Speed: 1.0ms preprocess, 605.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 620.0ms\n",
      "Speed: 2.0ms preprocess, 620.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 684.0ms\n",
      "Speed: 1.0ms preprocess, 684.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 746.0ms\n",
      "Speed: 2.0ms preprocess, 746.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 654.0ms\n",
      "Speed: 2.0ms preprocess, 654.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 603.0ms\n",
      "Speed: 2.0ms preprocess, 603.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 592.0ms\n",
      "Speed: 2.0ms preprocess, 592.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 589.0ms\n",
      "Speed: 1.0ms preprocess, 589.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 596.0ms\n",
      "Speed: 2.0ms preprocess, 596.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 597.0ms\n",
      "Speed: 1.0ms preprocess, 597.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 598.0ms\n",
      "Speed: 2.0ms preprocess, 598.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 592.0ms\n",
      "Speed: 2.0ms preprocess, 592.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 595.0ms\n",
      "Speed: 2.0ms preprocess, 595.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 596.0ms\n",
      "Speed: 2.0ms preprocess, 596.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 597.0ms\n",
      "Speed: 2.0ms preprocess, 597.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 600.0ms\n",
      "Speed: 2.0ms preprocess, 600.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 604.0ms\n",
      "Speed: 1.0ms preprocess, 604.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 601.0ms\n",
      "Speed: 2.0ms preprocess, 601.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 603.0ms\n",
      "Speed: 2.0ms preprocess, 603.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 594.0ms\n",
      "Speed: 2.0ms preprocess, 594.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 592.0ms\n",
      "Speed: 2.0ms preprocess, 592.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 sports ball, 2 chairs, 1 clock, 597.0ms\n",
      "Speed: 2.0ms preprocess, 597.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 600.0ms\n",
      "Speed: 2.0ms preprocess, 600.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 595.0ms\n",
      "Speed: 2.0ms preprocess, 595.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 599.0ms\n",
      "Speed: 1.0ms preprocess, 599.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 602.0ms\n",
      "Speed: 2.0ms preprocess, 602.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 596.0ms\n",
      "Speed: 2.0ms preprocess, 596.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 591.0ms\n",
      "Speed: 1.0ms preprocess, 591.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 595.0ms\n",
      "Speed: 2.0ms preprocess, 595.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 597.0ms\n",
      "Speed: 2.0ms preprocess, 597.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 590.0ms\n",
      "Speed: 2.0ms preprocess, 590.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 604.0ms\n",
      "Speed: 2.0ms preprocess, 604.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 605.0ms\n",
      "Speed: 2.0ms preprocess, 605.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 594.0ms\n",
      "Speed: 2.0ms preprocess, 594.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 596.0ms\n",
      "Speed: 2.0ms preprocess, 596.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 597.0ms\n",
      "Speed: 1.0ms preprocess, 597.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 588.0ms\n",
      "Speed: 1.0ms preprocess, 588.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 599.0ms\n",
      "Speed: 1.0ms preprocess, 599.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 597.0ms\n",
      "Speed: 1.0ms preprocess, 597.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 602.0ms\n",
      "Speed: 2.0ms preprocess, 602.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 599.0ms\n",
      "Speed: 2.0ms preprocess, 599.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 600.0ms\n",
      "Speed: 1.0ms preprocess, 600.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 600.0ms\n",
      "Speed: 3.0ms preprocess, 600.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 602.0ms\n",
      "Speed: 1.0ms preprocess, 602.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 602.0ms\n",
      "Speed: 2.0ms preprocess, 602.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 596.0ms\n",
      "Speed: 2.0ms preprocess, 596.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 594.0ms\n",
      "Speed: 2.0ms preprocess, 594.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 639.0ms\n",
      "Speed: 2.0ms preprocess, 639.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 639.0ms\n",
      "Speed: 2.0ms preprocess, 639.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 725.0ms\n",
      "Speed: 2.0ms preprocess, 725.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 664.0ms\n",
      "Speed: 3.0ms preprocess, 664.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 656.0ms\n",
      "Speed: 2.0ms preprocess, 656.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 623.0ms\n",
      "Speed: 2.0ms preprocess, 623.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 619.0ms\n",
      "Speed: 2.0ms preprocess, 619.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 614.0ms\n",
      "Speed: 2.0ms preprocess, 614.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 621.0ms\n",
      "Speed: 2.0ms preprocess, 621.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 619.0ms\n",
      "Speed: 2.0ms preprocess, 619.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 654.0ms\n",
      "Speed: 2.0ms preprocess, 654.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 750.0ms\n",
      "Speed: 2.0ms preprocess, 750.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 791.0ms\n",
      "Speed: 3.0ms preprocess, 791.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 739.0ms\n",
      "Speed: 2.0ms preprocess, 739.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 886.9ms\n",
      "Speed: 4.0ms preprocess, 886.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 718.1ms\n",
      "Speed: 5.0ms preprocess, 718.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 686.0ms\n",
      "Speed: 1.0ms preprocess, 686.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 701.2ms\n",
      "Speed: 5.0ms preprocess, 701.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 649.9ms\n",
      "Speed: 2.0ms preprocess, 649.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 667.6ms\n",
      "Speed: 2.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 634.3ms\n",
      "Speed: 2.0ms preprocess, 634.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 656.5ms\n",
      "Speed: 1.0ms preprocess, 656.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 644.6ms\n",
      "Speed: 4.0ms preprocess, 644.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 629.2ms\n",
      "Speed: 2.0ms preprocess, 629.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 644.8ms\n",
      "Speed: 1.0ms preprocess, 644.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 633.1ms\n",
      "Speed: 2.5ms preprocess, 633.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 tennis rackets, 2 chairs, 1 clock, 635.4ms\n",
      "Speed: 2.0ms preprocess, 635.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 638.1ms\n",
      "Speed: 1.0ms preprocess, 638.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 tennis rackets, 2 chairs, 1 clock, 654.0ms\n",
      "Speed: 2.0ms preprocess, 654.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 tennis rackets, 2 chairs, 1 clock, 650.5ms\n",
      "Speed: 3.0ms preprocess, 650.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 687.4ms\n",
      "Speed: 2.0ms preprocess, 687.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 629.7ms\n",
      "Speed: 2.0ms preprocess, 629.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 640.4ms\n",
      "Speed: 2.0ms preprocess, 640.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 656.6ms\n",
      "Speed: 3.0ms preprocess, 656.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 658.3ms\n",
      "Speed: 3.0ms preprocess, 658.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 651.0ms\n",
      "Speed: 2.0ms preprocess, 651.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 637.8ms\n",
      "Speed: 1.5ms preprocess, 637.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 636.5ms\n",
      "Speed: 2.0ms preprocess, 636.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 650.4ms\n",
      "Speed: 2.0ms preprocess, 650.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 636.6ms\n",
      "Speed: 1.9ms preprocess, 636.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 635.4ms\n",
      "Speed: 2.0ms preprocess, 635.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 641.3ms\n",
      "Speed: 2.0ms preprocess, 641.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 645.0ms\n",
      "Speed: 2.0ms preprocess, 645.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 643.7ms\n",
      "Speed: 2.0ms preprocess, 643.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 646.3ms\n",
      "Speed: 2.0ms preprocess, 646.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 624.2ms\n",
      "Speed: 2.0ms preprocess, 624.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 639.8ms\n",
      "Speed: 2.0ms preprocess, 639.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 645.7ms\n",
      "Speed: 4.0ms preprocess, 645.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 628.6ms\n",
      "Speed: 2.0ms preprocess, 628.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 640.8ms\n",
      "Speed: 2.0ms preprocess, 640.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 chairs, 1 clock, 638.4ms\n",
      "Speed: 3.0ms preprocess, 638.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 600.2ms\n",
      "Speed: 2.2ms preprocess, 600.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bench, 1 sports ball, 598.1ms\n",
      "Speed: 2.0ms preprocess, 598.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bench, 1 sports ball, 1 tennis racket, 594.7ms\n",
      "Speed: 2.0ms preprocess, 594.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bench, 1 sports ball, 598.8ms\n",
      "Speed: 2.0ms preprocess, 598.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bench, 1 sports ball, 615.2ms\n",
      "Speed: 2.0ms preprocess, 615.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bench, 1 sports ball, 641.1ms\n",
      "Speed: 2.0ms preprocess, 641.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 635.1ms\n",
      "Speed: 1.0ms preprocess, 635.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 1 chair, 630.1ms\n",
      "Speed: 2.0ms preprocess, 630.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 sports balls, 1 tennis racket, 1 chair, 639.2ms\n",
      "Speed: 3.0ms preprocess, 639.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 frisbee, 1 sports ball, 1 tennis racket, 1 chair, 671.7ms\n",
      "Speed: 3.0ms preprocess, 671.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 sports balls, 1 tennis racket, 1 chair, 706.7ms\n",
      "Speed: 2.0ms preprocess, 706.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 sports balls, 1 tennis racket, 2 chairs, 699.7ms\n",
      "Speed: 3.2ms preprocess, 699.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "player detections len:  137\n",
      "------------------------------\n",
      "Player detections done\n",
      "\n",
      "0: 384x640 (no detections), 456.6ms\n",
      "Speed: 3.0ms preprocess, 456.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 441.1ms\n",
      "Speed: 2.0ms preprocess, 441.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 494.7ms\n",
      "Speed: 2.0ms preprocess, 494.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 525.7ms\n",
      "Speed: 3.0ms preprocess, 525.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 480.6ms\n",
      "Speed: 4.0ms preprocess, 480.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 449.1ms\n",
      "Speed: 3.0ms preprocess, 449.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 420.1ms\n",
      "Speed: 2.0ms preprocess, 420.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 443.6ms\n",
      "Speed: 4.0ms preprocess, 443.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 432.1ms\n",
      "Speed: 3.0ms preprocess, 432.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 464.1ms\n",
      "Speed: 2.0ms preprocess, 464.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 433.1ms\n",
      "Speed: 2.0ms preprocess, 433.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 428.6ms\n",
      "Speed: 3.0ms preprocess, 428.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 419.1ms\n",
      "Speed: 3.0ms preprocess, 419.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 552.1ms\n",
      "Speed: 3.0ms preprocess, 552.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 466.1ms\n",
      "Speed: 2.0ms preprocess, 466.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 544.2ms\n",
      "Speed: 3.0ms preprocess, 544.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 485.6ms\n",
      "Speed: 3.0ms preprocess, 485.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 501.6ms\n",
      "Speed: 2.0ms preprocess, 501.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 425.6ms\n",
      "Speed: 2.0ms preprocess, 425.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 436.0ms\n",
      "Speed: 3.0ms preprocess, 436.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 415.0ms\n",
      "Speed: 2.0ms preprocess, 415.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 474.5ms\n",
      "Speed: 3.0ms preprocess, 474.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 506.6ms\n",
      "Speed: 3.0ms preprocess, 506.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 510.4ms\n",
      "Speed: 3.0ms preprocess, 510.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 483.4ms\n",
      "Speed: 3.0ms preprocess, 483.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 455.6ms\n",
      "Speed: 3.0ms preprocess, 455.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 446.1ms\n",
      "Speed: 2.0ms preprocess, 446.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 429.4ms\n",
      "Speed: 3.0ms preprocess, 429.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 438.9ms\n",
      "Speed: 3.0ms preprocess, 438.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 442.2ms\n",
      "Speed: 2.0ms preprocess, 442.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 446.1ms\n",
      "Speed: 3.0ms preprocess, 446.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 410.1ms\n",
      "Speed: 3.0ms preprocess, 410.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 449.6ms\n",
      "Speed: 3.0ms preprocess, 449.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 413.1ms\n",
      "Speed: 2.0ms preprocess, 413.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 416.1ms\n",
      "Speed: 3.0ms preprocess, 416.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 953.3ms\n",
      "Speed: 4.0ms preprocess, 953.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 678.7ms\n",
      "Speed: 3.0ms preprocess, 678.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 599.1ms\n",
      "Speed: 3.0ms preprocess, 599.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 517.6ms\n",
      "Speed: 4.0ms preprocess, 517.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 414.0ms\n",
      "Speed: 3.0ms preprocess, 414.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 429.0ms\n",
      "Speed: 2.0ms preprocess, 429.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 399.5ms\n",
      "Speed: 2.0ms preprocess, 399.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 399.1ms\n",
      "Speed: 3.0ms preprocess, 399.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 390.1ms\n",
      "Speed: 2.0ms preprocess, 390.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 405.1ms\n",
      "Speed: 2.0ms preprocess, 405.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 416.1ms\n",
      "Speed: 3.0ms preprocess, 416.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 424.1ms\n",
      "Speed: 3.0ms preprocess, 424.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 409.7ms\n",
      "Speed: 3.0ms preprocess, 409.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 411.8ms\n",
      "Speed: 3.0ms preprocess, 411.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 434.1ms\n",
      "Speed: 3.0ms preprocess, 434.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 396.1ms\n",
      "Speed: 3.0ms preprocess, 396.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 404.7ms\n",
      "Speed: 2.0ms preprocess, 404.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 421.7ms\n",
      "Speed: 2.0ms preprocess, 421.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 394.1ms\n",
      "Speed: 3.0ms preprocess, 394.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 420.8ms\n",
      "Speed: 2.0ms preprocess, 420.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 406.1ms\n",
      "Speed: 2.0ms preprocess, 406.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 466.7ms\n",
      "Speed: 3.0ms preprocess, 466.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 403.1ms\n",
      "Speed: 3.0ms preprocess, 403.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 401.1ms\n",
      "Speed: 3.0ms preprocess, 401.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 400.1ms\n",
      "Speed: 2.0ms preprocess, 400.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 391.9ms\n",
      "Speed: 2.0ms preprocess, 391.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 426.1ms\n",
      "Speed: 2.0ms preprocess, 426.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 412.6ms\n",
      "Speed: 3.0ms preprocess, 412.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 403.0ms\n",
      "Speed: 3.0ms preprocess, 403.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 395.0ms\n",
      "Speed: 2.0ms preprocess, 395.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 389.0ms\n",
      "Speed: 2.0ms preprocess, 389.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 406.1ms\n",
      "Speed: 2.0ms preprocess, 406.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 394.2ms\n",
      "Speed: 2.0ms preprocess, 394.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 419.1ms\n",
      "Speed: 2.0ms preprocess, 419.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 389.1ms\n",
      "Speed: 2.0ms preprocess, 389.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 411.2ms\n",
      "Speed: 2.0ms preprocess, 411.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 396.1ms\n",
      "Speed: 3.0ms preprocess, 396.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 399.1ms\n",
      "Speed: 2.0ms preprocess, 399.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 387.1ms\n",
      "Speed: 3.0ms preprocess, 387.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 398.1ms\n",
      "Speed: 2.0ms preprocess, 398.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 412.1ms\n",
      "Speed: 2.0ms preprocess, 412.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 479.7ms\n",
      "Speed: 2.0ms preprocess, 479.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 387.1ms\n",
      "Speed: 3.0ms preprocess, 387.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 391.1ms\n",
      "Speed: 2.0ms preprocess, 391.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 397.1ms\n",
      "Speed: 2.0ms preprocess, 397.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 388.1ms\n",
      "Speed: 3.0ms preprocess, 388.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 398.1ms\n",
      "Speed: 3.0ms preprocess, 398.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 410.1ms\n",
      "Speed: 3.0ms preprocess, 410.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 406.8ms\n",
      "Speed: 2.0ms preprocess, 406.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 407.1ms\n",
      "Speed: 2.0ms preprocess, 407.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 414.7ms\n",
      "Speed: 2.0ms preprocess, 414.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 420.1ms\n",
      "Speed: 3.0ms preprocess, 420.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 412.1ms\n",
      "Speed: 3.0ms preprocess, 412.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 399.0ms\n",
      "Speed: 3.0ms preprocess, 399.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 384.5ms\n",
      "Speed: 2.0ms preprocess, 384.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 403.2ms\n",
      "Speed: 3.0ms preprocess, 403.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 408.1ms\n",
      "Speed: 3.0ms preprocess, 408.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 414.1ms\n",
      "Speed: 2.0ms preprocess, 414.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 395.6ms\n",
      "Speed: 2.5ms preprocess, 395.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 394.6ms\n",
      "Speed: 2.0ms preprocess, 394.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 404.2ms\n",
      "Speed: 2.5ms preprocess, 404.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 470.1ms\n",
      "Speed: 2.0ms preprocess, 470.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 492.6ms\n",
      "Speed: 3.0ms preprocess, 492.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 426.6ms\n",
      "Speed: 3.0ms preprocess, 426.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 407.6ms\n",
      "Speed: 2.0ms preprocess, 407.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 400.1ms\n",
      "Speed: 3.0ms preprocess, 400.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 406.1ms\n",
      "Speed: 2.0ms preprocess, 406.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 405.1ms\n",
      "Speed: 3.0ms preprocess, 405.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 711.7ms\n",
      "Speed: 3.0ms preprocess, 711.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 880.7ms\n",
      "Speed: 7.0ms preprocess, 880.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 598.1ms\n",
      "Speed: 3.0ms preprocess, 598.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 469.6ms\n",
      "Speed: 3.0ms preprocess, 469.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 395.1ms\n",
      "Speed: 3.0ms preprocess, 395.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 429.1ms\n",
      "Speed: 2.0ms preprocess, 429.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 423.0ms\n",
      "Speed: 3.0ms preprocess, 423.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 419.0ms\n",
      "Speed: 3.0ms preprocess, 419.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 440.0ms\n",
      "Speed: 3.0ms preprocess, 440.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 393.6ms\n",
      "Speed: 2.0ms preprocess, 393.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 480.1ms\n",
      "Speed: 3.0ms preprocess, 480.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 488.6ms\n",
      "Speed: 2.0ms preprocess, 488.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 463.6ms\n",
      "Speed: 2.0ms preprocess, 463.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 425.2ms\n",
      "Speed: 2.0ms preprocess, 425.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 411.2ms\n",
      "Speed: 2.0ms preprocess, 411.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 403.1ms\n",
      "Speed: 2.0ms preprocess, 403.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 407.1ms\n",
      "Speed: 2.0ms preprocess, 407.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 410.1ms\n",
      "Speed: 2.0ms preprocess, 410.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 416.1ms\n",
      "Speed: 2.0ms preprocess, 416.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 403.2ms\n",
      "Speed: 2.0ms preprocess, 403.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 404.1ms\n",
      "Speed: 2.0ms preprocess, 404.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 395.2ms\n",
      "Speed: 3.0ms preprocess, 395.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 404.1ms\n",
      "Speed: 2.0ms preprocess, 404.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 398.1ms\n",
      "Speed: 3.0ms preprocess, 398.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 400.1ms\n",
      "Speed: 2.0ms preprocess, 400.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 388.6ms\n",
      "Speed: 2.0ms preprocess, 388.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 390.1ms\n",
      "Speed: 2.0ms preprocess, 390.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tennis ball, 378.1ms\n",
      "Speed: 1.0ms preprocess, 378.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 398.1ms\n",
      "Speed: 2.0ms preprocess, 398.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 527.5ms\n",
      "Speed: 1.0ms preprocess, 527.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 470.0ms\n",
      "Speed: 3.0ms preprocess, 470.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 415.5ms\n",
      "Speed: 2.0ms preprocess, 415.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 406.1ms\n",
      "Speed: 2.0ms preprocess, 406.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 389.1ms\n",
      "Speed: 2.0ms preprocess, 389.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "------------------------------\n",
      "Ball detections done\n",
      "------------------------------\n",
      "Keypoints prediction done\n",
      "[1, 2]\n",
      "Total frames: 137\n",
      "Frame 0 player bboxes: {1: [980.4599609375, 637.0431518554688, 1055.77734375, 793.9934692382812], 2: [807.610107421875, 180.91030883789062, 861.6381225585938, 268.9741516113281]}\n",
      "Frame 0 player bbox keys: dict_keys([1, 2])\n",
      "Frame 1 player bboxes: {1: [970.3583374023438, 638.0718383789062, 1054.623291015625, 793.1699829101562], 2: [809.86962890625, 178.47885131835938, 861.595703125, 268.9194641113281]}\n",
      "Frame 1 player bbox keys: dict_keys([1, 2])\n",
      "Frame 2 player bboxes: {1: [963.833984375, 637.9900512695312, 1053.609130859375, 797.0307006835938], 2: [809.7891235351562, 176.27023315429688, 861.6793823242188, 268.9959716796875]}\n",
      "Frame 2 player bbox keys: dict_keys([1, 2])\n",
      "Frame 3 player bboxes: {1: [960.3430786132812, 637.276611328125, 1049.8583984375, 800.1738891601562], 2: [808.9466552734375, 171.44602966308594, 862.3536376953125, 269.5549621582031]}\n",
      "Frame 3 player bbox keys: dict_keys([1, 2])\n",
      "Frame 4 player bboxes: {1: [958.74365234375, 635.2914428710938, 1047.7264404296875, 803.7584838867188], 2: [808.2677612304688, 166.85377502441406, 862.3580322265625, 267.56988525390625]}\n",
      "Frame 4 player bbox keys: dict_keys([1, 2])\n",
      "Frame 5 player bboxes: {1: [959.3540649414062, 633.7037353515625, 1046.15478515625, 805.2584838867188], 2: [807.95849609375, 164.2327880859375, 862.8886108398438, 266.1035461425781]}\n",
      "Frame 5 player bbox keys: dict_keys([1, 2])\n",
      "Frame 6 player bboxes: {1: [959.7432250976562, 633.1592407226562, 1045.6893310546875, 805.6810302734375], 2: [807.8612060546875, 163.42564392089844, 863.0689086914062, 265.5860290527344]}\n",
      "Frame 6 player bbox keys: dict_keys([1, 2])\n",
      "Frame 7 player bboxes: {1: [958.2040405273438, 632.915283203125, 1042.9912109375, 806.2351684570312], 2: [807.7332153320312, 163.21194458007812, 862.8829345703125, 263.4925231933594]}\n",
      "Frame 7 player bbox keys: dict_keys([1, 2])\n",
      "Frame 8 player bboxes: {1: [955.361572265625, 633.004638671875, 1042.9072265625, 807.8136596679688], 2: [807.1907348632812, 163.38204956054688, 862.9024047851562, 262.8526306152344]}\n",
      "Frame 8 player bbox keys: dict_keys([1, 2])\n",
      "Frame 9 player bboxes: {1: [951.5355834960938, 634.663330078125, 1044.2581787109375, 810.0289306640625], 2: [806.095703125, 163.4976348876953, 862.39697265625, 263.03271484375]}\n",
      "Frame 9 player bbox keys: dict_keys([1, 2])\n",
      "Frame 10 player bboxes: {1: [942.376953125, 637.8912963867188, 1045.4732666015625, 811.7039184570312], 2: [805.6041870117188, 163.754638671875, 862.018798828125, 264.5955810546875]}\n",
      "Frame 10 player bbox keys: dict_keys([1, 2])\n",
      "Frame 11 player bboxes: {1: [933.0123901367188, 642.08740234375, 1046.645263671875, 818.8218994140625], 2: [805.5827026367188, 165.39816284179688, 861.390869140625, 266.6592102050781]}\n",
      "Frame 11 player bbox keys: dict_keys([1, 2])\n",
      "Frame 12 player bboxes: {1: [929.3685913085938, 643.6423950195312, 1047.1435546875, 821.4090576171875], 2: [805.5955810546875, 166.07650756835938, 860.9358520507812, 267.45037841796875]}\n",
      "Frame 12 player bbox keys: dict_keys([1, 2])\n",
      "Frame 13 player bboxes: {1: [925.1563110351562, 647.66796875, 1049.3470458984375, 828.0919189453125], 2: [805.8463134765625, 168.40744018554688, 858.6614990234375, 270.88714599609375]}\n",
      "Frame 13 player bbox keys: dict_keys([1, 2])\n",
      "Frame 14 player bboxes: {1: [922.47998046875, 654.1177978515625, 1051.449462890625, 833.6580810546875], 2: [807.5386352539062, 172.99993896484375, 856.2445068359375, 272.33331298828125]}\n",
      "Frame 14 player bbox keys: dict_keys([1, 2])\n",
      "Frame 15 player bboxes: {1: [921.2837524414062, 659.8085327148438, 1052.2647705078125, 841.0508422851562], 2: [809.20166015625, 176.8679962158203, 855.1332397460938, 276.0107727050781]}\n",
      "Frame 15 player bbox keys: dict_keys([1, 2])\n",
      "Frame 16 player bboxes: {1: [920.5485229492188, 663.865478515625, 1052.939208984375, 846.6907348632812], 2: [808.4476318359375, 182.3448028564453, 854.5868530273438, 277.9178466796875]}\n",
      "Frame 16 player bbox keys: dict_keys([1, 2])\n",
      "Frame 17 player bboxes: {1: [918.8782348632812, 666.8331909179688, 1053.05859375, 848.9572143554688], 2: [807.8805541992188, 188.21621704101562, 853.1867065429688, 278.91522216796875]}\n",
      "Frame 17 player bbox keys: dict_keys([1, 2])\n",
      "Frame 18 player bboxes: {1: [918.3584594726562, 667.87353515625, 1053.1234130859375, 849.6536865234375], 2: [807.6774291992188, 190.3175048828125, 852.722412109375, 279.2361755371094]}\n",
      "Frame 18 player bbox keys: dict_keys([1, 2])\n",
      "Frame 19 player bboxes: {1: [917.9501953125, 668.0289916992188, 1047.595703125, 849.1820678710938], 2: [807.3778686523438, 193.3651885986328, 853.01025390625, 278.9067687988281]}\n",
      "Frame 19 player bbox keys: dict_keys([1, 2])\n",
      "Frame 20 player bboxes: {1: [918.859619140625, 667.384521484375, 1034.7080078125, 847.8120727539062], 2: [807.434814453125, 195.24725341796875, 854.031005859375, 278.6520080566406]}\n",
      "Frame 20 player bbox keys: dict_keys([1, 2])\n",
      "Frame 21 player bboxes: {1: [919.2163696289062, 666.7882690429688, 1016.8017578125, 844.3521728515625], 2: [807.4219970703125, 195.22784423828125, 856.62646484375, 278.32757568359375]}\n",
      "Frame 21 player bbox keys: dict_keys([1, 2])\n",
      "Frame 22 player bboxes: {1: [918.6822509765625, 667.1203002929688, 1008.6507568359375, 840.923828125], 2: [807.8014526367188, 193.49464416503906, 859.4092407226562, 278.2359619140625]}\n",
      "Frame 22 player bbox keys: dict_keys([1, 2])\n",
      "Frame 23 player bboxes: {1: [915.62451171875, 667.5923461914062, 1003.9762573242188, 839.4951171875], 2: [809.0303344726562, 191.7248992919922, 871.4589233398438, 278.2122497558594]}\n",
      "Frame 23 player bbox keys: dict_keys([1, 2])\n",
      "Frame 24 player bboxes: {1: [914.7639770507812, 667.7921752929688, 1002.5083618164062, 838.9437866210938], 2: [809.486572265625, 191.0140380859375, 876.0120849609375, 278.2071838378906]}\n",
      "Frame 24 player bbox keys: dict_keys([1, 2])\n",
      "Frame 25 player bboxes: {1: [908.67138671875, 668.3946533203125, 1001.3085327148438, 839.639404296875], 2: [812.0389404296875, 188.44589233398438, 882.5438232421875, 276.3290100097656]}\n",
      "Frame 25 player bbox keys: dict_keys([1, 2])\n",
      "Frame 26 player bboxes: {1: [902.7867431640625, 668.4308471679688, 1000.341064453125, 839.9889526367188], 2: [818.2833251953125, 185.3828125, 887.1165161132812, 274.026123046875]}\n",
      "Frame 26 player bbox keys: dict_keys([1, 2])\n",
      "Frame 27 player bboxes: {1: [900.912109375, 665.9810180664062, 997.8660278320312, 840.1385498046875], 2: [827.5671997070312, 182.5098876953125, 893.3336791992188, 273.02716064453125]}\n",
      "Frame 27 player bbox keys: dict_keys([1, 2])\n",
      "Frame 28 player bboxes: {1: [900.5667724609375, 661.428466796875, 994.2009887695312, 839.0580444335938], 2: [835.2726440429688, 180.38644409179688, 900.3425903320312, 272.3944091796875]}\n",
      "Frame 28 player bbox keys: dict_keys([1, 2])\n",
      "Frame 29 player bboxes: {1: [902.5734252929688, 654.947021484375, 992.5462646484375, 836.7905883789062], 2: [841.3857421875, 178.19708251953125, 905.7135620117188, 271.07647705078125]}\n",
      "Frame 29 player bbox keys: dict_keys([1, 2])\n",
      "Frame 30 player bboxes: {1: [903.4527587890625, 652.4404296875, 992.0260009765625, 835.9003295898438], 2: [843.6475219726562, 177.38943481445312, 907.6729125976562, 270.6075134277344]}\n",
      "Frame 30 player bbox keys: dict_keys([1, 2])\n",
      "Frame 31 player bboxes: {1: [903.0760498046875, 646.7916870117188, 990.706787109375, 832.706787109375], 2: [848.2579345703125, 177.31849670410156, 910.8098754882812, 270.0110778808594]}\n",
      "Frame 31 player bbox keys: dict_keys([1, 2])\n",
      "Frame 32 player bboxes: {1: [902.1339111328125, 642.5343627929688, 994.07470703125, 825.6777954101562], 2: [855.2363891601562, 176.92242431640625, 913.4364624023438, 269.94744873046875]}\n",
      "Frame 32 player bbox keys: dict_keys([1, 2])\n",
      "Frame 33 player bboxes: {1: [902.6948852539062, 637.4539184570312, 999.316162109375, 813.7017211914062], 2: [865.02099609375, 176.7777557373047, 914.2764282226562, 269.708251953125]}\n",
      "Frame 33 player bbox keys: dict_keys([1, 2])\n",
      "Frame 34 player bboxes: {1: [902.6780395507812, 632.55029296875, 1002.885498046875, 802.7002563476562], 2: [872.3264770507812, 178.14158630371094, 915.7028198242188, 269.4974670410156]}\n",
      "Frame 34 player bbox keys: dict_keys([1, 2])\n",
      "Frame 35 player bboxes: {1: [903.5090942382812, 627.1365966796875, 1004.532958984375, 797.1835327148438], 2: [878.6900024414062, 179.90028381347656, 917.264892578125, 268.37744140625]}\n",
      "Frame 35 player bbox keys: dict_keys([1, 2])\n",
      "Frame 36 player bboxes: {1: [903.8577880859375, 625.2777709960938, 1005.2200317382812, 795.3607788085938], 2: [880.5889282226562, 180.489501953125, 917.631591796875, 267.9710693359375]}\n",
      "Frame 36 player bbox keys: dict_keys([1, 2])\n",
      "Frame 37 player bboxes: {1: [902.9518432617188, 621.7146606445312, 1008.0682983398438, 789.9139404296875], 2: [885.8400268554688, 181.47613525390625, 923.5641479492188, 267.7429504394531]}\n",
      "Frame 37 player bbox keys: dict_keys([1, 2])\n",
      "Frame 38 player bboxes: {1: [898.1129150390625, 617.9605102539062, 1012.0033569335938, 779.001220703125], 2: [890.7466430664062, 181.88577270507812, 936.9885864257812, 267.4261474609375]}\n",
      "Frame 38 player bbox keys: dict_keys([1, 2])\n",
      "Frame 39 player bboxes: {1: [894.8250122070312, 615.3690795898438, 1017.0177612304688, 765.3348388671875], 2: [896.1904296875, 181.3448486328125, 947.7237548828125, 267.28668212890625]}\n",
      "Frame 39 player bbox keys: dict_keys([1, 2])\n",
      "Frame 40 player bboxes: {1: [894.5820922851562, 614.1072998046875, 1022.5070190429688, 755.7578125], 2: [899.7785034179688, 180.2494659423828, 954.7142333984375, 265.7620544433594]}\n",
      "Frame 40 player bbox keys: dict_keys([1, 2])\n",
      "Frame 41 player bboxes: {1: [895.73974609375, 612.690185546875, 1027.8455810546875, 752.5950317382812], 2: [902.7501220703125, 180.0754852294922, 957.8120727539062, 264.10076904296875]}\n",
      "Frame 41 player bbox keys: dict_keys([1, 2])\n",
      "Frame 42 player bboxes: {1: [896.241455078125, 612.2561645507812, 1030.1322021484375, 751.6199340820312], 2: [903.7125854492188, 180.0146484375, 958.8970336914062, 263.57757568359375]}\n",
      "Frame 42 player bbox keys: dict_keys([1, 2])\n",
      "Frame 43 player bboxes: {1: [901.9942016601562, 610.8072509765625, 1027.017333984375, 751.69970703125], 2: [904.6931762695312, 179.429931640625, 959.2764892578125, 262.58465576171875]}\n",
      "Frame 43 player bbox keys: dict_keys([1, 2])\n",
      "Frame 44 player bboxes: {1: [910.261962890625, 607.815673828125, 1023.7512817382812, 751.7523803710938], 2: [906.2955932617188, 178.181640625, 959.2216186523438, 261.3787841796875]}\n",
      "Frame 44 player bbox keys: dict_keys([1, 2])\n",
      "Frame 45 player bboxes: {1: [914.8436889648438, 603.3029174804688, 1013.7929077148438, 752.0753173828125], 2: [908.6060791015625, 176.43838500976562, 959.1566162109375, 259.7065734863281]}\n",
      "Frame 45 player bbox keys: dict_keys([1, 2])\n",
      "Frame 46 player bboxes: {1: [918.3672485351562, 596.9049072265625, 997.0496826171875, 752.3963012695312], 2: [911.2513427734375, 171.44955444335938, 958.5030517578125, 257.9878845214844]}\n",
      "Frame 46 player bbox keys: dict_keys([1, 2])\n",
      "Frame 47 player bboxes: {1: [922.2479858398438, 588.7809448242188, 990.1470336914062, 751.8984985351562], 2: [913.0054321289062, 167.94862365722656, 959.2401123046875, 256.50933837890625]}\n",
      "Frame 47 player bbox keys: dict_keys([1, 2])\n",
      "Frame 48 player bboxes: {1: [923.4219360351562, 585.7048950195312, 988.252685546875, 751.818359375], 2: [913.5433349609375, 166.65602111816406, 959.4103393554688, 255.9808807373047]}\n",
      "Frame 48 player bbox keys: dict_keys([1, 2])\n",
      "Frame 49 player bboxes: {1: [921.12158203125, 579.5095825195312, 994.3746337890625, 749.2095336914062], 2: [913.5960693359375, 165.13787841796875, 959.260009765625, 254.13934326171875]}\n",
      "Frame 49 player bbox keys: dict_keys([1, 2])\n",
      "Frame 50 player bboxes: {1: [920.3670043945312, 571.2037353515625, 1001.4456176757812, 744.2916870117188], 2: [913.42138671875, 163.8702392578125, 960.2603759765625, 252.48953247070312]}\n",
      "Frame 50 player bbox keys: dict_keys([1, 2])\n",
      "Frame 51 player bboxes: {1: [919.5870361328125, 562.1478271484375, 989.5460205078125, 736.2446899414062], 2: [912.829345703125, 162.97447204589844, 963.1008911132812, 250.514892578125]}\n",
      "Frame 51 player bbox keys: dict_keys([1, 2])\n",
      "Frame 52 player bboxes: {1: [918.1731567382812, 553.236083984375, 980.91943359375, 730.6209716796875], 2: [912.2839965820312, 163.04283142089844, 964.2283325195312, 247.58653259277344]}\n",
      "Frame 52 player bbox keys: dict_keys([1, 2])\n",
      "Frame 53 player bboxes: {1: [918.5504760742188, 545.00341796875, 977.2221069335938, 724.7218017578125], 2: [909.5645751953125, 163.7231903076172, 966.4386596679688, 245.66445922851562]}\n",
      "Frame 53 player bbox keys: dict_keys([1, 2])\n",
      "Frame 54 player bboxes: {1: [918.6382446289062, 541.9960327148438, 976.0753173828125, 722.54833984375], 2: [908.5241088867188, 164.02334594726562, 967.1842041015625, 244.9993896484375]}\n",
      "Frame 54 player bbox keys: dict_keys([1, 2])\n",
      "Frame 55 player bboxes: {1: [919.7579345703125, 538.6600952148438, 975.3463134765625, 714.8646850585938], 2: [908.1063232421875, 165.026611328125, 969.162353515625, 245.07704162597656]}\n",
      "Frame 55 player bbox keys: dict_keys([1, 2])\n",
      "Frame 56 player bboxes: {1: [923.8900756835938, 534.9254760742188, 978.18701171875, 706.3960571289062], 2: [908.4618530273438, 166.8898162841797, 970.338134765625, 245.8682403564453]}\n",
      "Frame 56 player bbox keys: dict_keys([1, 2])\n",
      "Frame 57 player bboxes: {1: [923.4678344726562, 533.2078247070312, 986.6777954101562, 698.2958374023438], 2: [909.2435913085938, 170.63768005371094, 970.9325561523438, 246.2421112060547]}\n",
      "Frame 57 player bbox keys: dict_keys([1, 2])\n",
      "Frame 58 player bboxes: {1: [924.0986938476562, 532.87939453125, 994.35009765625, 692.9361572265625], 2: [910.6488037109375, 172.05421447753906, 971.0180053710938, 246.1773223876953]}\n",
      "Frame 58 player bbox keys: dict_keys([1, 2])\n",
      "Frame 59 player bboxes: {1: [924.8739624023438, 533.3535766601562, 1002.4482421875, 691.4415893554688], 2: [911.1752319335938, 172.5034637451172, 971.3328857421875, 246.41165161132812]}\n",
      "Frame 59 player bbox keys: dict_keys([1, 2])\n",
      "Frame 60 player bboxes: {1: [925.1596069335938, 533.6726684570312, 1005.6513671875, 691.0985107421875], 2: [911.3331909179688, 172.70684814453125, 971.4553833007812, 246.58424377441406]}\n",
      "Frame 60 player bbox keys: dict_keys([1, 2])\n",
      "Frame 61 player bboxes: {1: [923.9109497070312, 533.4817504882812, 1007.7135620117188, 691.7939453125], 2: [908.4639282226562, 171.48057556152344, 970.8023681640625, 246.93051147460938]}\n",
      "Frame 61 player bbox keys: dict_keys([1, 2])\n",
      "Frame 62 player bboxes: {1: [921.2131958007812, 532.2987060546875, 1006.8506469726562, 692.3396606445312], 2: [900.5809326171875, 170.64410400390625, 968.0211791992188, 243.736328125]}\n",
      "Frame 62 player bbox keys: dict_keys([1, 2])\n",
      "Frame 63 player bboxes: {1: [921.183837890625, 529.494140625, 1002.0874633789062, 692.044189453125], 2: [895.831298828125, 168.87025451660156, 966.1467895507812, 242.0613250732422]}\n",
      "Frame 63 player bbox keys: dict_keys([1, 2])\n",
      "Frame 64 player bboxes: {1: [923.0175170898438, 525.2487182617188, 995.8240966796875, 691.0407104492188], 2: [891.4054565429688, 165.9003143310547, 951.59814453125, 241.716796875]}\n",
      "Frame 64 player bbox keys: dict_keys([1, 2])\n",
      "Frame 65 player bboxes: {1: [925.9937744140625, 519.6716918945312, 991.8184814453125, 688.3467407226562], 2: [887.3949584960938, 164.55416870117188, 939.9017944335938, 241.56234741210938]}\n",
      "Frame 65 player bbox keys: dict_keys([1, 2])\n",
      "Frame 66 player bboxes: {1: [927.0968627929688, 517.6495971679688, 990.3388671875, 687.4061889648438], 2: [886.0079345703125, 164.0153045654297, 935.8358154296875, 241.55178833007812]}\n",
      "Frame 66 player bbox keys: dict_keys([1, 2])\n",
      "Frame 67 player bboxes: {1: [928.5060424804688, 515.0230712890625, 990.1746215820312, 681.244140625], 2: [883.9204711914062, 165.05975341796875, 933.0523681640625, 242.2378387451172]}\n",
      "Frame 67 player bbox keys: dict_keys([1, 2])\n",
      "Frame 68 player bboxes: {1: [930.1900634765625, 512.53564453125, 989.5648803710938, 669.3732299804688], 2: [880.9464111328125, 163.66429138183594, 932.01220703125, 244.71604919433594]}\n",
      "Frame 68 player bbox keys: dict_keys([1, 2])\n",
      "Frame 69 player bboxes: {1: [928.79833984375, 511.02581787109375, 988.6914672851562, 659.64794921875], 2: [877.3505859375, 160.7900390625, 931.09521484375, 245.9645233154297]}\n",
      "Frame 69 player bbox keys: dict_keys([1, 2])\n",
      "Frame 70 player bboxes: {1: [927.1535034179688, 509.38299560546875, 988.0424194335938, 655.8209838867188], 2: [872.9339599609375, 160.7378692626953, 930.4204711914062, 247.124755859375]}\n",
      "Frame 70 player bbox keys: dict_keys([1, 2])\n",
      "Frame 71 player bboxes: {1: [924.34765625, 505.19232177734375, 988.04638671875, 652.6859130859375], 2: [868.8488159179688, 161.04872131347656, 929.3258666992188, 247.48855590820312]}\n",
      "Frame 71 player bbox keys: dict_keys([1, 2])\n",
      "Frame 72 player bboxes: {1: [923.3103637695312, 503.73095703125, 988.0824584960938, 651.7240600585938], 2: [867.388427734375, 161.2470703125, 928.9363403320312, 247.6398162841797]}\n",
      "Frame 72 player bbox keys: dict_keys([1, 2])\n",
      "Frame 73 player bboxes: {1: [920.7438354492188, 498.98291015625, 987.1735229492188, 650.8890991210938], 2: [865.8719482421875, 161.7650909423828, 928.6156616210938, 247.43521118164062]}\n",
      "Frame 73 player bbox keys: dict_keys([1, 2])\n",
      "Frame 74 player bboxes: {1: [918.8331909179688, 493.22747802734375, 985.9298706054688, 648.3076782226562], 2: [861.803955078125, 162.3188018798828, 928.1332397460938, 247.59144592285156]}\n",
      "Frame 74 player bbox keys: dict_keys([1, 2])\n",
      "Frame 75 player bboxes: {1: [917.3482055664062, 488.0321350097656, 984.0231323242188, 639.6685791015625], 2: [863.5034790039062, 160.08665466308594, 925.0535278320312, 248.086669921875]}\n",
      "Frame 75 player bbox keys: dict_keys([1, 2])\n",
      "Frame 76 player bboxes: {1: [915.1800537109375, 482.191162109375, 983.951904296875, 630.0463256835938], 2: [865.358154296875, 158.03150939941406, 919.0367431640625, 248.32696533203125]}\n",
      "Frame 76 player bbox keys: dict_keys([1, 2])\n",
      "Frame 77 player bboxes: {1: [911.9743041992188, 477.45556640625, 983.3934936523438, 620.1798706054688], 2: [862.6461181640625, 156.99732971191406, 915.7392578125, 248.7379150390625]}\n",
      "Frame 77 player bbox keys: dict_keys([1, 2])\n",
      "Frame 78 player bboxes: {1: [910.834228515625, 475.89117431640625, 983.1394653320312, 616.6614990234375], 2: [861.7008666992188, 156.5937042236328, 914.7506103515625, 248.84690856933594]}\n",
      "Frame 78 player bbox keys: dict_keys([1, 2])\n",
      "Frame 79 player bboxes: {1: [911.281982421875, 473.3354797363281, 983.221923828125, 612.0970458984375], 2: [859.2354125976562, 155.57559204101562, 913.8765258789062, 247.07545471191406]}\n",
      "Frame 79 player bbox keys: dict_keys([1, 2])\n",
      "Frame 80 player bboxes: {1: [906.6488647460938, 471.1531677246094, 984.5219116210938, 605.1686401367188], 2: [861.7464599609375, 155.3582000732422, 913.5929565429688, 246.15988159179688]}\n",
      "Frame 80 player bbox keys: dict_keys([1, 2])\n",
      "Frame 81 player bboxes: {1: [896.3959350585938, 469.96954345703125, 985.5590209960938, 600.555419921875], 2: [866.1493530273438, 154.6412353515625, 913.67431640625, 246.8194580078125]}\n",
      "Frame 81 player bbox keys: dict_keys([1, 2])\n",
      "Frame 82 player bboxes: {1: [887.031005859375, 469.646728515625, 987.0187377929688, 594.658935546875], 2: [866.3759155273438, 154.7678680419922, 914.1071166992188, 247.3044891357422]}\n",
      "Frame 82 player bbox keys: dict_keys([1, 2])\n",
      "Frame 83 player bboxes: {1: [880.7206420898438, 469.6634216308594, 987.8471069335938, 591.41015625], 2: [864.8397216796875, 155.79344177246094, 914.5430908203125, 249.17002868652344]}\n",
      "Frame 83 player bbox keys: dict_keys([1, 2])\n",
      "Frame 84 player bboxes: {1: [878.1883544921875, 469.75604248046875, 988.1874389648438, 590.50048828125], 2: [864.3174438476562, 156.20294189453125, 914.7236328125, 249.88587951660156]}\n",
      "Frame 84 player bbox keys: dict_keys([1, 2])\n",
      "Frame 85 player bboxes: {1: [874.8660278320312, 468.9730529785156, 988.00390625, 589.2791137695312], 2: [861.7498168945312, 158.48501586914062, 915.134765625, 250.30520629882812]}\n",
      "Frame 85 player bbox keys: dict_keys([1, 2])\n",
      "Frame 86 player bboxes: {1: [872.081298828125, 466.4591369628906, 987.7459106445312, 589.105712890625], 2: [860.2172241210938, 159.68914794921875, 915.9432373046875, 251.7489776611328]}\n",
      "Frame 86 player bbox keys: dict_keys([1, 2])\n",
      "Frame 87 player bboxes: {1: [871.2133178710938, 464.76312255859375, 987.375244140625, 587.8858642578125], 2: [859.5242919921875, 161.7608642578125, 915.803955078125, 252.70016479492188]}\n",
      "Frame 87 player bbox keys: dict_keys([1, 2])\n",
      "Frame 88 player bboxes: {1: [869.630615234375, 462.34942626953125, 986.1942138671875, 585.9365844726562], 2: [859.3268432617188, 164.23910522460938, 917.277099609375, 253.60028076171875]}\n",
      "Frame 88 player bbox keys: dict_keys([1, 2])\n",
      "Frame 89 player bboxes: {1: [867.6145629882812, 459.0195007324219, 984.6478881835938, 583.35009765625], 2: [859.2993774414062, 166.1626739501953, 918.0767822265625, 254.0669403076172]}\n",
      "Frame 89 player bbox keys: dict_keys([1, 2])\n",
      "Frame 90 player bboxes: {1: [866.9453735351562, 457.815673828125, 984.0922241210938, 582.5342407226562], 2: [859.3009033203125, 166.85665893554688, 918.4155883789062, 254.25038146972656]}\n",
      "Frame 90 player bbox keys: dict_keys([1, 2])\n",
      "Frame 91 player bboxes: {1: [859.5108032226562, 454.8594665527344, 978.6777954101562, 579.6793212890625], 2: [859.4033203125, 166.9197540283203, 918.2212524414062, 254.0765380859375]}\n",
      "Frame 91 player bbox keys: dict_keys([1, 2])\n",
      "Frame 92 player bboxes: {1: [853.4976196289062, 451.22528076171875, 965.1080322265625, 573.4244384765625], 2: [859.6421508789062, 167.2131805419922, 922.2493286132812, 253.94412231445312]}\n",
      "Frame 92 player bbox keys: dict_keys([1, 2])\n",
      "Frame 93 player bboxes: {1: [847.4231567382812, 447.20977783203125, 951.908203125, 570.8477783203125], 2: [861.6024780273438, 167.84738159179688, 925.7461547851562, 253.95591735839844]}\n",
      "Frame 93 player bbox keys: dict_keys([1, 2])\n",
      "Frame 94 player bboxes: {1: [842.431396484375, 441.7739562988281, 939.062744140625, 568.4640502929688], 2: [866.9332885742188, 168.49981689453125, 931.7416381835938, 254.2204132080078]}\n",
      "Frame 94 player bbox keys: dict_keys([1, 2])\n",
      "Frame 95 player bboxes: {1: [840.3157348632812, 436.26318359375, 923.9069213867188, 566.3756713867188], 2: [871.5336303710938, 168.69407653808594, 936.9348754882812, 254.37660217285156]}\n",
      "Frame 95 player bbox keys: dict_keys([1, 2])\n",
      "Frame 96 player bboxes: {1: [839.8792724609375, 434.30523681640625, 918.7091064453125, 565.6781616210938], 2: [873.2791137695312, 168.73501586914062, 938.9066772460938, 254.42787170410156]}\n",
      "Frame 96 player bbox keys: dict_keys([1, 2])\n",
      "Frame 97 player bboxes: {1: [838.089599609375, 430.9010925292969, 906.5535278320312, 565.25146484375], 2: [882.3397216796875, 168.67861938476562, 939.4690551757812, 254.2728729248047]}\n",
      "Frame 97 player bbox keys: dict_keys([1, 2])\n",
      "Frame 98 player bboxes: {1: [834.0001220703125, 427.112060546875, 893.820556640625, 565.1788940429688], 2: [890.4129028320312, 167.0604705810547, 939.9171752929688, 254.501220703125]}\n",
      "Frame 98 player bbox keys: dict_keys([1, 2])\n",
      "Frame 99 player bboxes: {1: [831.1138916015625, 423.5818786621094, 886.81005859375, 564.1688842773438], 2: [895.3411254882812, 165.51063537597656, 940.7589721679688, 255.31211853027344]}\n",
      "Frame 99 player bbox keys: dict_keys([1, 2])\n",
      "Frame 100 player bboxes: {1: [827.4747314453125, 420.3553466796875, 883.3150024414062, 563.91015625], 2: [898.1482543945312, 164.5557403564453, 941.3009033203125, 255.94813537597656]}\n",
      "Frame 100 player bbox keys: dict_keys([1, 2])\n",
      "Frame 101 player bboxes: {1: [822.3106689453125, 417.710693359375, 879.1260375976562, 563.365234375], 2: [901.5120239257812, 164.07736206054688, 942.2548828125, 257.53228759765625]}\n",
      "Frame 101 player bbox keys: dict_keys([1, 2])\n",
      "Frame 102 player bboxes: {1: [820.6220703125, 416.85394287109375, 877.8984985351562, 563.201904296875], 2: [902.5372924804688, 163.8961944580078, 942.5191650390625, 258.0568542480469]}\n",
      "Frame 102 player bbox keys: dict_keys([1, 2])\n",
      "Frame 103 player bboxes: {1: [816.5386962890625, 416.5575866699219, 875.5157470703125, 560.9424438476562], 2: [903.9266967773438, 164.6260223388672, 943.4850463867188, 258.8597717285156]}\n",
      "Frame 103 player bbox keys: dict_keys([1, 2])\n",
      "Frame 104 player bboxes: {1: [813.5638427734375, 416.6800842285156, 869.9888916015625, 557.861328125], 2: [906.4183349609375, 166.07334899902344, 944.6300048828125, 259.83502197265625]}\n",
      "Frame 104 player bbox keys: dict_keys([1, 2])\n",
      "Frame 105 player bboxes: {1: [809.3636474609375, 416.51641845703125, 863.525390625, 554.6099243164062], 2: [908.719482421875, 168.03271484375, 945.5958251953125, 262.4836120605469]}\n",
      "Frame 105 player bbox keys: dict_keys([1, 2])\n",
      "Frame 106 player bboxes: {1: [804.0697631835938, 415.20343017578125, 856.888671875, 550.6840209960938], 2: [911.68359375, 171.7601318359375, 946.8880615234375, 264.4942932128906]}\n",
      "Frame 106 player bbox keys: dict_keys([1, 2])\n",
      "Frame 107 player bboxes: {1: [798.0857543945312, 413.7782897949219, 849.2350463867188, 548.1859741210938], 2: [914.6332397460938, 174.49673461914062, 948.3236083984375, 265.69915771484375]}\n",
      "Frame 107 player bbox keys: dict_keys([1, 2])\n",
      "Frame 108 player bboxes: {1: [796.1090087890625, 413.32598876953125, 846.7046508789062, 547.2850952148438], 2: [915.53857421875, 175.53152465820312, 948.7687377929688, 266.1224060058594]}\n",
      "Frame 108 player bbox keys: dict_keys([1, 2])\n",
      "Frame 109 player bboxes: {1: [791.3773193359375, 410.1405334472656, 841.2886352539062, 546.3946533203125], 2: [918.8431396484375, 176.15565490722656, 951.0242919921875, 265.7307434082031]}\n",
      "Frame 109 player bbox keys: dict_keys([1, 2])\n",
      "Frame 110 player bboxes: {1: [788.1304931640625, 408.5667419433594, 839.6829223632812, 544.1552124023438], 2: [922.1044921875, 175.94583129882812, 953.599609375, 265.527099609375]}\n",
      "Frame 110 player bbox keys: dict_keys([1, 2])\n",
      "Frame 111 player bboxes: {1: [781.2418212890625, 405.47906494140625, 839.633544921875, 542.6341552734375], 2: [924.3416748046875, 175.4652862548828, 957.1648559570312, 265.7842102050781]}\n",
      "Frame 111 player bbox keys: dict_keys([1, 2])\n",
      "Frame 112 player bboxes: {1: [771.616943359375, 403.6532897949219, 838.4859619140625, 541.3408203125], 2: [925.4462280273438, 172.8294677734375, 962.360595703125, 265.5433349609375]}\n",
      "Frame 112 player bbox keys: dict_keys([1, 2])\n",
      "Frame 113 player bboxes: {1: [764.5730590820312, 403.1798400878906, 837.2191772460938, 540.6470947265625], 2: [926.5966186523438, 171.01869201660156, 967.7037353515625, 267.2255859375]}\n",
      "Frame 113 player bbox keys: dict_keys([1, 2])\n",
      "Frame 114 player bboxes: {1: [761.8076782226562, 403.0791015625, 836.8220825195312, 540.4583129882812], 2: [926.9635620117188, 170.3394012451172, 969.776123046875, 267.7970275878906]}\n",
      "Frame 114 player bbox keys: dict_keys([1, 2])\n",
      "Frame 115 player bboxes: {1: [758.3148193359375, 403.1993713378906, 835.8378295898438, 540.3432006835938], 2: [927.6627807617188, 169.06243896484375, 973.0800170898438, 266.8870544433594]}\n",
      "Frame 115 player bbox keys: dict_keys([1, 2])\n",
      "Frame 116 player bboxes: {1: [757.958740234375, 405.189453125, 832.0667114257812, 540.5247192382812], 2: [928.2279663085938, 168.78387451171875, 978.2236328125, 266.1597595214844]}\n",
      "Frame 116 player bbox keys: dict_keys([1, 2])\n",
      "Frame 117 player bboxes: {1: [758.1241455078125, 407.6697692871094, 826.8519897460938, 540.7425537109375], 2: [929.004150390625, 168.8472137451172, 983.2647094726562, 266.263916015625]}\n",
      "Frame 117 player bbox keys: dict_keys([1, 2])\n",
      "Frame 118 player bboxes: {1: [758.7286376953125, 408.6039123535156, 819.535400390625, 540.5892333984375], 2: [929.9493408203125, 169.3677215576172, 987.8141479492188, 266.2376403808594]}\n",
      "Frame 118 player bbox keys: dict_keys([1, 2])\n",
      "Frame 119 player bboxes: {1: [756.9541015625, 408.3876647949219, 810.2188720703125, 540.769775390625], 2: [932.74951171875, 172.561767578125, 990.3226318359375, 267.72186279296875]}\n",
      "Frame 119 player bbox keys: dict_keys([1, 2])\n",
      "Frame 120 player bboxes: {1: [756.5499877929688, 408.30889892578125, 807.1790161132812, 540.8611450195312], 2: [933.8324584960938, 173.7611846923828, 991.1911010742188, 268.2561340332031]}\n",
      "Frame 120 player bbox keys: dict_keys([1, 2])\n",
      "Frame 121 player bboxes: {1: [753.4979858398438, 407.62261962890625, 798.241455078125, 540.6995849609375], 2: [936.7939453125, 175.38121032714844, 993.696533203125, 268.8998718261719]}\n",
      "Frame 121 player bbox keys: dict_keys([1, 2])\n",
      "Frame 122 player bboxes: {1: [750.8702392578125, 407.13397216796875, 790.3333129882812, 540.6301879882812], 2: [941.8794555664062, 176.14276123046875, 995.9089965820312, 269.14654541015625]}\n",
      "Frame 122 player bbox keys: dict_keys([1, 2])\n",
      "Frame 123 player bboxes: {1: [746.3135986328125, 406.60784912109375, 787.0668334960938, 540.7420654296875], 2: [948.585205078125, 176.07601928710938, 998.5433349609375, 269.1494445800781]}\n",
      "Frame 123 player bbox keys: dict_keys([1, 2])\n",
      "Frame 124 player bboxes: {1: [737.886962890625, 405.9435119628906, 786.410888671875, 540.706298828125], 2: [955.2996826171875, 175.8582305908203, 1000.447998046875, 269.890625]}\n",
      "Frame 124 player bbox keys: dict_keys([1, 2])\n",
      "Frame 125 player bboxes: {}\n",
      "Frame 125 player bbox keys: No bboxes\n",
      "Frame 126 player bboxes: {}\n",
      "Frame 126 player bbox keys: No bboxes\n",
      "Frame 127 player bboxes: {}\n",
      "Frame 127 player bbox keys: No bboxes\n",
      "Frame 128 player bboxes: {}\n",
      "Frame 128 player bbox keys: No bboxes\n",
      "Frame 129 player bboxes: {}\n",
      "Frame 129 player bbox keys: No bboxes\n",
      "Frame 130 player bboxes: {}\n",
      "Frame 130 player bbox keys: No bboxes\n",
      "Frame 131 player bboxes: {}\n",
      "Frame 131 player bbox keys: No bboxes\n",
      "Frame 132 player bboxes: {}\n",
      "Frame 132 player bbox keys: No bboxes\n",
      "Frame 133 player bboxes: {}\n",
      "Frame 133 player bbox keys: No bboxes\n",
      "Frame 134 player bboxes: {}\n",
      "Frame 134 player bbox keys: No bboxes\n",
      "Frame 135 player bboxes: {}\n",
      "Frame 135 player bbox keys: No bboxes\n",
      "Frame 136 player bboxes: {}\n",
      "Frame 136 player bbox keys: No bboxes\n",
      "[1, 2]\n",
      "Skipping frame 125: No player detections available.\n",
      "Skipping frame 126: No player detections available.\n",
      "Skipping frame 127: No player detections available.\n",
      "Skipping frame 128: No player detections available.\n",
      "Skipping frame 129: No player detections available.\n",
      "Skipping frame 130: No player detections available.\n",
      "Skipping frame 131: No player detections available.\n",
      "Skipping frame 132: No player detections available.\n",
      "Skipping frame 133: No player detections available.\n",
      "Skipping frame 134: No player detections available.\n",
      "Skipping frame 135: No player detections available.\n",
      "Skipping frame 136: No player detections available.\n",
      "------------------------------\n",
      "Conversion to minicourt coordinates done\n",
      "Processing ball hit from frame 49 to 78\n",
      "Ball hit by player 1\n",
      "Updated player stats for frame 49\n",
      "------------------------------\n",
      "Player stats done\n",
      "Invalid bounding box coordinates: nan, nan, nan, nan\n",
      "Invalid bounding box coordinates: nan, nan, nan, nan\n",
      "Invalid bounding box coordinates: nan, nan, nan, nan\n",
      "Invalid bounding box coordinates: nan, nan, nan, nan\n",
      "Invalid bounding box coordinates: nan, nan, nan, nan\n",
      "Invalid bounding box coordinates: nan, nan, nan, nan\n",
      "------------------------------\n",
      "Minicourt done\n",
      "------------------------------\n",
      "Video saved successfully\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
